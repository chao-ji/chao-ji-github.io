<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-08-09T12:03:04+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">SuperComputer’s Blog</title><subtitle>Dedicated to the clarity in explaining Machine Learning. </subtitle><entry><title type="html">Beam Search</title><link href="http://localhost:4000/jekyll/update/2019/01/24/Beam_Search.html" rel="alternate" type="text/html" title="Beam Search" /><published>2019-01-24T03:34:28+08:00</published><updated>2019-01-24T03:34:28+08:00</updated><id>http://localhost:4000/jekyll/update/2019/01/24/Beam_Search</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/01/24/Beam_Search.html">&lt;p&gt;Intelligently generating a coherent sequence of words is an important feature of a wide range of modern NLP applications like machine translation, chatbots, question answering, etc.. The process of sequence generation boils down to repeatedly performing a simple action: spitting out the next word based on the current word (and implicitly all the words that have been generated so far), which is implemented by a function or subroutine that computes a probability distribution over all legitimate next words and decides which word to output according to that prob distribution.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/example.png&quot; width=&quot;600&quot; /&gt;
  &lt;br /&gt; Figure 1. Generate sequence by repeatedly picking the next word.
&lt;/p&gt;

&lt;p&gt;Roughly speaking, we are interested in finding a sequence that is most likely to be generated, quantified by the &lt;em&gt;probability score&lt;/em&gt; of the sequence, or equivalently the sum of logarithm of probabilities (sum-of-log-probs) of its constituent words. Although it might be straightforward to let the function output whichever word with the largest probability throughout the entire process, it’s worth noting that the function has a unique property in that it takes in &lt;em&gt;its own&lt;/em&gt; output at previous time steps to compute the current output, and as a result the prob distribution of next word may &lt;em&gt;change&lt;/em&gt; depending on the choice we made in the past. As we will see shortly, this property has subtle implication on our word-picking strategy — picking words with lower probabilities, a seemingly non-optimal move, may eventually pay off as it unlocks access to choices that may lead to overall higher score of the entire sequence.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/greedy.png&quot; width=&quot;300&quot; /&gt;&lt;img src=&quot;/assets/20190124/optimal.png&quot; width=&quot;300&quot; /&gt;
  &lt;br /&gt; Figure 2. Left: sequence &quot;ABC&quot; found by greedy search with probability 0.048; Right: optimal sequence &quot;ACB&quot; with probability 0.054. Note the probability distribution diverges starting from time step 3, because different choices were made at the preceding step (&quot;C&quot; vs. &quot;B&quot;). The search leading to the globally optimal sequence made a locally non-optimal choice at time step 2. Image credit: [http://www.d2l.ai/chapter_recurrent-modern/beam-search.html]
&lt;/p&gt;

&lt;h2 id=&quot;intuition&quot;&gt;Intuition&lt;/h2&gt;

&lt;p&gt;So what would be a good word-picking strategy? Notice that we are essentially facing a &lt;em&gt;tree search&lt;/em&gt; problem – We start off with a single partial sequence that contains only the special word &lt;code class=&quot;highlighter-rouge&quot;&gt;SOS&lt;/code&gt; (Start Of Sequence), together with its sum-of-log-probs (i.e. &lt;script type=&quot;math/tex&quot;&gt;0=\log 1&lt;/script&gt;). We would like to consider each word from the vocabulary as a potential next word of the current partial sequence, so we duplicate it to &lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; (vocabulary size) copies and each copy gets extended with a different word. Then we update the sum-of-log-probs of the &lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; partial sequences that are now one word longer. Obviously we are going to end up with an exponential search space of &lt;script type=&quot;math/tex&quot;&gt;V^n&lt;/script&gt; sequences if we were to repeat this process for &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; steps, which would make any algorithm that seeks to &lt;em&gt;exhaustively&lt;/em&gt; search for the sequence with largest sum-of-log-probs computationally intractable.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/exhaustive.png&quot; width=&quot;500&quot; /&gt;
  &lt;br /&gt; Figure 3. Exhaustive Search expands the search tree unboundedly.
&lt;/p&gt;

&lt;p&gt;Rather than let the search space grow unboundedly with the length of sequence, &lt;a href=&quot;https://en.wikipedia.org/wiki/Beam_search&quot;&gt;Beam Search&lt;/a&gt; limits the total number of sequences that we are tracking to a constant &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; (a.k.a. &lt;strong&gt;beam width&lt;/strong&gt;). Like exhaustive search, when we expand the current set of &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; candidate partial sequences (a.k.a. beams) of length &lt;script type=&quot;math/tex&quot;&gt;l&lt;/script&gt;, we consider each of the &lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; vocabulary words as the potential next word, leading to &lt;script type=&quot;math/tex&quot;&gt;kV&lt;/script&gt; sequences of length &lt;script type=&quot;math/tex&quot;&gt;l + 1&lt;/script&gt;. &lt;em&gt;Unlike&lt;/em&gt; exhaustive search, we prune all but the top &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; most promising (with largest sum-of-log-probs) candidates, bringing the “candidate pool” back to the original size. However, the downside is that there is no guarantee Beam Search is going to find the same optimal solution as the exhaustive search, because the goal state leading to optimality may have been pruned halfway. In this sense, Beam Search is a &lt;em&gt;heuristic&lt;/em&gt; searching algorithm.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/beam width.png&quot; width=&quot;500&quot; /&gt;
  &lt;br /&gt; Figure 4. Beam Search prunes candidate sequences to a constant size k=4. Candidates first get extended by one word and expanded by a factor of V=3, then get pruned back to beam width k=4. 
&lt;/p&gt;

&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;
&lt;p&gt;So far we have briefly gone over the general ideas of Beam Search. In this part, we are going to get to the nuts and bolts of it that you should understand to implement it correctly.&lt;/p&gt;

&lt;h3 id=&quot;each-beam-maintains-its-own-set-of-states&quot;&gt;Each beam maintains its own set of states&lt;/h3&gt;
&lt;p&gt;At this point you should already be convinced that we need to keep track of the status of &lt;em&gt;each beam&lt;/em&gt; as we grow the partial sequences. We create ndarrays &lt;code class=&quot;highlighter-rouge&quot;&gt;active_seqs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;active_log_probs&lt;/code&gt; with shape &lt;code class=&quot;highlighter-rouge&quot;&gt;[batch_size, beam_width, partial_seq_len]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;[batch_size, beam_width]&lt;/code&gt;, respectively, where the slices into the beam dimension, &lt;code class=&quot;highlighter-rouge&quot;&gt;active_seqs[:, j]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;active_log_probs[:, j]&lt;/code&gt;, store the &lt;em&gt;status&lt;/em&gt; of beam &lt;code class=&quot;highlighter-rouge&quot;&gt;j&lt;/code&gt;, i.e. the list of word IDs making that partial sequence and the corresponding sum-of-log-prob.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/duplicate.png&quot; width=&quot;800&quot; /&gt;
  &lt;br /&gt; Figure 5. Initial setup of active partial sequences &amp;amp; their sum-of-log-probs, and what they look like a few steps into the searching process. For example, the sum-of-log-prob of the partial sequence [SOS, ..., 523] equals -0.334 aftern Step n.
&lt;/p&gt;

&lt;p&gt;As shown in Figure 5, we started with a single copy of the initial partial sequence (&lt;code class=&quot;highlighter-rouge&quot;&gt;SOS&lt;/code&gt;) and its sum-of-log-prob (&lt;code class=&quot;highlighter-rouge&quot;&gt;0.0&lt;/code&gt;), and we need to duplicate them to &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width&lt;/code&gt; copies so each beam gets its own set of states. However, if we were to simply copy the initial value of sum-of-log-prob across all beams, we would end up with identical partial sequences after “Step 1”. The trick is to “suppress” the sum-of-log-probs of partial squences coming from all but the first beam, so only those sequences will “survive” after the pruning (See Figure 6).&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/initial_step.png&quot; width=&quot;800&quot; /&gt;
  &lt;br /&gt; Figure 6. Computing logits of &quot;next words&quot; (by calling get_next()) and updating the sum-of-log-probs (by adding &quot;logits&quot; with duplicated &quot;active_log_probs[i]&quot;). Note that the distributions of the logits of &quot;next words&quot; are the same across different beams because the same input &quot;SOS&quot; was fed to get_next(); and the -inf entries in &quot;active_log_probs[i]&quot; push the scores of partial sequences from Beam 2, 3, and 4 to -inf, so we are effectively picking top scoring candidates only from Beam 1.

&lt;/p&gt;

&lt;p&gt;You may have noticed that some variable names we referenced are prefixed with &lt;code class=&quot;highlighter-rouge&quot;&gt;active_&lt;/code&gt;. By that we mean they are still being &lt;em&gt;actively&lt;/em&gt; extended, untill we stumble across &lt;code class=&quot;highlighter-rouge&quot;&gt;EOS&lt;/code&gt; (like &lt;code class=&quot;highlighter-rouge&quot;&gt;SOS&lt;/code&gt;), which is another special word from the vocabulary that signals the &lt;em&gt;End of Sequence&lt;/em&gt;. We say those partial sequences ending with &lt;code class=&quot;highlighter-rouge&quot;&gt;EOS&lt;/code&gt; are in the &lt;em&gt;finished&lt;/em&gt; state (as opposed to &lt;em&gt;active&lt;/em&gt;), and their states will be stored in ndarrays other than &lt;code class=&quot;highlighter-rouge&quot;&gt;active_seqs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;active_log_probs&lt;/code&gt;. Intuitively, active sequence plays the role of “frontiers” as we explore the search space, whereas finished sequence records those that are indeed “finished” and are ready to output. We want to make sure that the width of the frontier (i.e. number of active sequences) is unchanged throughout the course of Beam Search.&lt;/p&gt;

&lt;h3 id=&quot;how-states-are-updated&quot;&gt;How states are updated&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/overview.png&quot; width=&quot;800&quot; /&gt;
  &lt;br /&gt; Figure 7. Overview of how active and finished sequences are updated within a single step of Beam Search. 
&lt;/p&gt;

&lt;p&gt;Now we are ready to explain exactly what happens in a single step of Beam Search, where the partial sequences get extended by one word and their sum-of-log-probs get updated accordingly. The main logic can be broken down into three substeps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Grow Active Sequences&lt;/li&gt;
  &lt;li&gt;Gather Top Active Sequences&lt;/li&gt;
  &lt;li&gt;Gather Top Finished Sequences&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;grow-active-sequences&quot;&gt;Grow Active Sequences&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/step_n.png&quot; width=&quot;800&quot; /&gt;
  &lt;img src=&quot;/assets/20190124/grow_active_seq.png&quot; width=&quot;800&quot; /&gt;
  &lt;br /&gt; Figure 8: How the &quot;frontiers&quot; of the exploration are expanded and pruned. 
&lt;/p&gt;

&lt;p&gt;We first need to evaluate the likelihood of each word in the vocabulary being the next word of the current set of candidate partial sequences &lt;code class=&quot;highlighter-rouge&quot;&gt;active_seqs[i]&lt;/code&gt;. We call the function &lt;code class=&quot;highlighter-rouge&quot;&gt;get_next()&lt;/code&gt; that outputs the &lt;code class=&quot;highlighter-rouge&quot;&gt;logits&lt;/code&gt; of each potential next word whose index ranges from &lt;code class=&quot;highlighter-rouge&quot;&gt;0&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;vocab_size - 1&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;logits&lt;/code&gt; will be converted to log-prob and added to the existing sum-of-log-probs &lt;code class=&quot;highlighter-rouge&quot;&gt;active_log_probs[i]&lt;/code&gt;. We will reduce the set of candidate partial sequences from &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width * vocab_size&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;k = beam_width * 2&lt;/code&gt; by picking the top &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt; scoring candidates (“Candidate Pool” in Figure 7 and 8).&lt;/p&gt;

&lt;p&gt;The reason &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width * 2&lt;/code&gt; as opposed to &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width&lt;/code&gt; is that we have to make sure the number of active sequences is still &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width&lt;/code&gt; at the end of each step, and letting &lt;code class=&quot;highlighter-rouge&quot;&gt;k = beam_width * 2&lt;/code&gt; guarantees that we would always end up with &lt;em&gt;at least&lt;/em&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width&lt;/code&gt; active sequences to pick from (convince yourself this is so).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;grow_active_seqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;active_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;active_log_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;active_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Grows the search tree of the active sequences by one level, and gathers
  the top-scoring `2 * beam_width` candidates.

  Args:
    active_seq: tensor of shape [batch_size, beam_width, partial_seq_len]
    active_log_probs: tensor of shape [batch_size, beam_width]
    active_cache: nested dict containing tensors of shape [batch_size,
      beam_width, ...]
    get_next: a callable that computes the logits of next words.

  Returns:
    updated_seq: tensor of shape [batch_size, beam_width * 2,
      partial_seq_len + 1]
    updated_log_probs: tensor of shape [batch_size, beam_width * 2]
    updated_active_cache: nested dict containing tensors of shape [batch_size,
      beam_width * 2, ...]
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As shown in the function signature of &lt;code class=&quot;highlighter-rouge&quot;&gt;grow_active_seqs&lt;/code&gt;, the input arguments &lt;code class=&quot;highlighter-rouge&quot;&gt;active_seq&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;active_log_probs&lt;/code&gt; maintain the status of active sequences. &lt;code class=&quot;highlighter-rouge&quot;&gt;active_cache&lt;/code&gt; keeps track of the status of words that have been generated &lt;em&gt;earlier than&lt;/em&gt; the “current word” (for example, the already computed key and value vectors of words that we pay attention to in the Transformer model, or the recurrent state vectors in RNN sequence model), which will be updated as well in this function. &lt;code class=&quot;highlighter-rouge&quot;&gt;get_next&lt;/code&gt; is a callback function that computes the logits (equivalently the prob distribution) of next words, and will be executed within &lt;code class=&quot;highlighter-rouge&quot;&gt;grow_active_seqs&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;gather-top-active-sequences&quot;&gt;Gather Top Active Sequences&lt;/h4&gt;

&lt;p&gt;Given the &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width * 2&lt;/code&gt; candidates in which at least &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width&lt;/code&gt; are active, it would be straightforward to pick &amp;amp; gather top &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width&lt;/code&gt; scoring active parital sequences.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/gather_top_active.png&quot; width=&quot;800&quot; /&gt;
  &lt;br /&gt; Figure 9: Gather top active sequences. The active sequence with sum-of-log-prob -3.068 was NOT picked because it's not ranked among the top &quot;beam_width&quot;. 
&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gather_top_active_seqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;updated_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updated_log_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updated_active_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Gather top scoring active sequences from the candidate pool.
  Args:
    updated_seq: tensor of shape [batch_size, beam_width * 2, 
      partial_seq_len + 1]
    updated_log_probs: tensor of shape [batch_size, beam_width * 2]
    updated_active_cache: nested dict containing tensors of shape [batch_size,
      beam_width * 2, ...]

  Returns:
    new_active_seq: tensor of shape [batch_size, beam_width,
      partial_seq_len + 1]
    new_log_probs: tensor of shape [batch_size, beam_width]
    new_active_cache: nested dict containing tensors of shape [batch_size,
      beam_width, ...]
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;gather-top-finished-sequences&quot;&gt;Gather Top Finished Sequences&lt;/h4&gt;
&lt;p&gt;Unlike the case for active sequences, it will be a little more complicated to update the &lt;em&gt;finished&lt;/em&gt; sequences because not only do we need to pick &lt;em&gt;finished&lt;/em&gt; sequences from the Candidate Pool, but also cross-check with those that are already finished in &lt;em&gt;previous&lt;/em&gt; steps. We need to combine the new and the old and pick the top &lt;code class=&quot;highlighter-rouge&quot;&gt;beam_width&lt;/code&gt; scoring finished sequences.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/gather_top_finished.png&quot; width=&quot;800&quot; /&gt;
  &lt;br /&gt; Figure 10: Gather top finished sequences. The sequences finished in previous steps are colored in cyan. We combine those picked from the Candidate Pool with those that are previously finished, and pick the top scoring ones. Note that the previously finished sequences are shorter and will be zero-padded to match the length of those picked from the Candidate Pool. 
&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gather_top_finished_seqs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;updated_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updated_log_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;old_finished_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;old_finished_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  Args:
    updated_seq: tensor of shape [batch_size, beam_width * 2, 
      partial_seq_len + 1]
    updated_log_probs: tensor of shape [batch_size, beam_width * 2]
    old_finished_seq: tensor of shape [batch_size, num_finished, 
      partial_seq_len]
    olf_finished_score: tensor of shape [batch_size, num_finished] 

  Returns:
    new_finished_seq: tensor of shape [batch_size, beam_width, 
      partial_seq_len + 1]
    new_finished_score: tensor of shape [batch_size, beam_width]
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;when-to-terminate-search&quot;&gt;When to Terminate Search&lt;/h4&gt;

&lt;p&gt;We haven’t talked about when we should stop searching. Typically, we specify a hyperparameter &lt;code class=&quot;highlighter-rouge&quot;&gt;max_seq_len&lt;/code&gt; that controls the maximum number of words a sequence can have. We terminate the growth of a sequence when the length reaches &lt;code class=&quot;highlighter-rouge&quot;&gt;max_seq_len&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Is there any other scenario where the searching should be terminated even before &lt;code class=&quot;highlighter-rouge&quot;&gt;max_seq_len&lt;/code&gt; is reached? Remember that the sum-of-log-probs of active partial sequencs are always updated by adding a negative value (i.e. log-prob of the “next words”). So if the maximum sum-of-log-prob of active sequences is less than the minimum sum-of-log-prob of finished sequences (over all beams), the active sequences would &lt;em&gt;never&lt;/em&gt; overtake finished ones in terms of the sum-of-log-prob scores, and we should stop searching as there will be no newly finished sequences.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/20190124/when_to_terminate.png&quot; width=&quot;800&quot; /&gt;
  &lt;br /&gt; Figure 11: The scenario where we should stop updating the status of active and finished sequences.
&lt;/p&gt;

&lt;h4 id=&quot;implementation-in-python--tensorflow&quot;&gt;Implementation in Python &amp;amp; TensorFlow&lt;/h4&gt;

&lt;p&gt;A reference implementation is available &lt;a href=&quot;https://github.com/chao-ji/nlp_toolkit/blob/master/beam_search.py&quot;&gt;here&lt;/a&gt;. You need to create an instance of &lt;code class=&quot;highlighter-rouge&quot;&gt;BeamSearch&lt;/code&gt; where a callable &lt;code class=&quot;highlighter-rouge&quot;&gt;get_next&lt;/code&gt; is supplied that computes the logits of next words (check the function signature listed below). Then call the instance method &lt;code class=&quot;highlighter-rouge&quot;&gt;search&lt;/code&gt; that returns the finished sequenced found by Beam Search. For examples that performs Beam Search using this implementation, refer to &lt;a href=&quot;https://github.com/chao-ji/tf-transformer&quot;&gt;Transformer&lt;/a&gt; and &lt;a href=&quot;https://github.com/chao-ji/tf-seq2seq&quot;&gt;Seq2Seq&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BeamSearch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
               &lt;span class=&quot;n&quot;&gt;get_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
               &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;beam_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;max_decode_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;eos_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Searches for sequences with greatest log-probs.

    Args:
      initial_ids: tensor of shape [batch_size] 
      initial_cache: nested dict containing tensors of shape [batch_size,
        beam_width, ...] 

    Returns:
      finished_seqs: tensor of shape [batch_size, beam_width, seq_len]
      finished_scores: tensor of shape [batch_size, beam_width]
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Compute logits based on input word IDs.
  Args:
    inputs: tensor of shape [batch_size, 1]

  Returns:
    logits: tensor of shape [batch_size, vocab_size]
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;decoder_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#[batch_size, hidden_size]
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#[batch_size, vocab_size]
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Intelligently generating a coherent sequence of words is an important feature of a wide range of modern NLP applications like machine translation, chatbots, question answering, etc.. The process of sequence generation boils down to repeatedly performing a simple action: spitting out the next word based on the current word (and implicitly all the words that have been generated so far), which is implemented by a function or subroutine that computes a probability distribution over all legitimate next words and decides which word to output according to that prob distribution.</summary></entry><entry><title type="html">Optimality Proof of GAN</title><link href="http://localhost:4000/jekyll/update/2019/01/03/GAN_proof.html" rel="alternate" type="text/html" title="Optimality Proof of GAN" /><published>2019-01-03T17:14:28+08:00</published><updated>2019-01-03T17:14:28+08:00</updated><id>http://localhost:4000/jekyll/update/2019/01/03/GAN_proof</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2019/01/03/GAN_proof.html">&lt;p&gt;This post documents a detailed proof of the conditions to achieve optimality for the original GAN.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;First, let’s recap the GAN formulation. We have a minimax game&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\displaystyle\min_{\theta_{G}}\max_{\theta_{D}} V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)} \log D(x; \theta_{D}) + \mathbb{E}_{z \sim p_{z}(z)} \log (1 - D(G(z; \theta_{G}); \theta_{D}))&lt;/script&gt;

&lt;p&gt;The goal is to &lt;strong&gt;maximize&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;V(D, G)&lt;/script&gt; over &lt;script type=&quot;math/tex&quot;&gt;\theta_{D}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;G&lt;/script&gt; is fixed, while at the same time &lt;strong&gt;minimize&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;V(D, G)&lt;/script&gt; over &lt;script type=&quot;math/tex&quot;&gt;\theta_{G}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; is fixed.&lt;/p&gt;

&lt;p&gt;In this formulation, both &lt;script type=&quot;math/tex&quot;&gt;G(x; \theta_{G})&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;D(x; \theta_{D})&lt;/script&gt; are neural networks (e.g. Multilayer Perceptron or CNN) parameterized by &lt;script type=&quot;math/tex&quot;&gt;\theta_{G}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\theta_{D}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We want to find&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The condition that &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; must satisfy to maximize  &lt;script type=&quot;math/tex&quot;&gt;V(D, G)&lt;/script&gt;, while keeping &lt;script type=&quot;math/tex&quot;&gt;G&lt;/script&gt; fixed (Proposition 1)&lt;/li&gt;
  &lt;li&gt;The condition that &lt;script type=&quot;math/tex&quot;&gt;G&lt;/script&gt; must satisfy to miminize  &lt;script type=&quot;math/tex&quot;&gt;V(D, G)&lt;/script&gt;, while keeping &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; fixed (Proposition 2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A note on notation and assumption:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Both &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; are random vectors (i.e. vector where each component is a random variable).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Proposition 1:&lt;/strong&gt; When &lt;script type=&quot;math/tex&quot;&gt;\theta_{G}&lt;/script&gt; is fixed, the &lt;strong&gt;optimal Discriminator&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D(x; \theta_{D}) = 
\frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_{g}(x)}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Proof&lt;/strong&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
V(G, D) &amp; = \int_{x}  p_{\text{data}} (x) \log D(x; \theta_{D}) \mathrm{d}x + \int_{z} p_{z}(z) \log (1 - D(g(z); \theta_{D})) \mathrm{d}z \\
&amp; = \int_{x} \left( p_{\text{data}} (x) \log D(x; \theta_{D}) + p_{g}(x) \log (1 - D(x; \theta_{D})) \right) \mathrm{d}x
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Note that &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; is a random vector where &lt;script type=&quot;math/tex&quot;&gt;z \sim p_{z}(z)&lt;/script&gt;, so &lt;script type=&quot;math/tex&quot;&gt;x = g(z)&lt;/script&gt; is also a random vector that follows some distribution denoted as  &lt;script type=&quot;math/tex&quot;&gt;p_{g}(x)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Because &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is integrated out, &lt;script type=&quot;math/tex&quot;&gt;V(G, D)&lt;/script&gt; only depends on &lt;script type=&quot;math/tex&quot;&gt;\theta_{D}&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;V(G, D)&lt;/script&gt; is maximized if the expression being integrated&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f = p_{\text{data}} (x) \log D(x; \theta_{D}) + p_{g}(x) \log (1 - D(x; \theta_{D}))&lt;/script&gt;

&lt;p&gt;is maximized.&lt;/p&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;y = D(x; \theta_{D})&lt;/script&gt;. Then &lt;script type=&quot;math/tex&quot;&gt;f = p_{\text{data}} (x) \log y + p_{g}(x) \log (1 - y)&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial y} f = \frac{p_{\text{data}} (x)} {y} - \frac{p_{g}(x)}{1 - y} = 0&lt;/script&gt;

&lt;p&gt;It follows that &lt;script type=&quot;math/tex&quot;&gt;y = D(x; \theta_{D}) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_{g}(x)}&lt;/script&gt; is necessary condition for achieving optimum.&lt;/p&gt;

&lt;p&gt;We also have
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\frac{\partial^{2} f}{\partial y^{2}} = - \frac{p_{\text{data}} (x)}{y^2} - \frac{ p_{g}(x)  }{(1 - y)^{2}} &lt; 0 %]]&gt;&lt;/script&gt;
, because &lt;script type=&quot;math/tex&quot;&gt;y \in (0, 1)&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;p_{\text{data}} (x) &gt; 0&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;p_{g}(x) &gt; 0&lt;/script&gt;. So &lt;script type=&quot;math/tex&quot;&gt;f&lt;/script&gt; achieves maximum at &lt;script type=&quot;math/tex&quot;&gt;y = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_{g}(x)}&lt;/script&gt;. &lt;strong&gt;End of Proof.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proposition 2:&lt;/strong&gt; When &lt;script type=&quot;math/tex&quot;&gt;\theta_{D}&lt;/script&gt; is optimal and fixed, then we have &lt;script type=&quot;math/tex&quot;&gt;p_{g}(x) = p_{\text{data}}(x)&lt;/script&gt; almost everywhere, where &lt;script type=&quot;math/tex&quot;&gt;p_{g}&lt;/script&gt; is the probability distribution of the samples &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; generatated from the &lt;strong&gt;optimal Generator&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When &lt;script type=&quot;math/tex&quot;&gt;D^{*}&lt;/script&gt; is optimal and fixed, we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;V(G, D^{*}) = \int_x \left( p_{\text{data}} (x) \log \frac{p_{\text{data}}(x)}{ p_{\text{data}}(x) + p_{g}(x)} + p_{g} (x) \log \frac{p_{g}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \right) \mathrm{d} x&lt;/script&gt;

&lt;p&gt;We denote &lt;script type=&quot;math/tex&quot;&gt;C(G) = V(G, D^{*})&lt;/script&gt; to indicate that &lt;script type=&quot;math/tex&quot;&gt;V(G, D^{*})&lt;/script&gt; is a now function of &lt;script type=&quot;math/tex&quot;&gt;\theta_{G}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Next we will show the relationship between &lt;script type=&quot;math/tex&quot;&gt;C(G)&lt;/script&gt; and the Jenson-Shannon Divergence (between &lt;script type=&quot;math/tex&quot;&gt;p_{\text{data}}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;p_{g}&lt;/script&gt;):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
D_{\text{JS}}(p_{\text{data}} \| p_{g})  = &amp;  \frac{1}{2}  D_{\text{KL}} (p_{\text{data}} \| \frac{p_{\text{data}}+p_{g}}{2}) + \frac{1}{2}  D_{\text{KL}} (p_{g} \| \frac{p_{\text{data}}+p_{g}}{2}) \\
 = &amp;  \frac{1}{2} \int_x p_{\text{data}} (x) \log \frac{2p_{\text{data}}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \mathrm{d}x + \frac{1}{2} \int_x p_{g} (x) \log \frac{2p_{g}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \mathrm{d}x \\ 
 = &amp; \frac{1}{2} \int_x \left( p_{\text{data}} (x) \log \frac{2p_{\text{data}}(x)}{ p_{\text{data}}(x) + p_{g}(x)} + p_{g} (x) \log \frac{2p_{g}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \right) \mathrm{d}x \\ 
 = &amp; \frac{1}{2} \int_x  p_{\text{data}} (x) \left( \log 2 +  \log \frac{p_{\text{data}}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \right) \mathrm{d} x + \\
   &amp; \frac{1}{2} \int_x  p_{g} (x) \left( \log 2 +  \log \frac{p_{g}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \right) \mathrm{d} x \\ 
 = &amp; \frac{1}{2} \log 2 + \frac{1}{2} \int_x  p_{\text{data}} (x) \log \frac{p_{\text{data}}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \mathrm{d} x + \\
   &amp; \frac{1}{2} \log 2 + \frac{1}{2} \int_x  p_{g} (x) \log \frac{p_{g}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \mathrm{d} x \\ 
= &amp; \log 2 + \frac{1}{2}  \int_x \left( p_{\text{data}} (x) \log \frac{p_{\text{data}}(x)}{ p_{\text{data}}(x) + p_{g}(x)} + p_{g} (x) \log \frac{p_{g}(x)}{ p_{\text{data}}(x) + p_{g}(x)} \right) \mathrm{d} x \\
= &amp; \log 2 + \frac{1}{2} C(G)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;It follows that &lt;script type=&quot;math/tex&quot;&gt;C(G) = 2 D_{\text{JS}}(p_{\text{data}} \| p_{g}) - 2 \log 2&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;C(G)&lt;/script&gt; is minimized only when &lt;script type=&quot;math/tex&quot;&gt;D_{\text{JS}}(p_{\text{data}} \| p_{g}) = 0&lt;/script&gt;, or the two probability distributions &lt;script type=&quot;math/tex&quot;&gt;p_{\text{data}} = p_{g}(x)&lt;/script&gt; almost everywhere. &lt;strong&gt;End of proof.&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">This post documents a detailed proof of the conditions to achieve optimality for the original GAN.</summary></entry><entry><title type="html">From Likelihood Maximization to Loss Minimization</title><link href="http://localhost:4000/jekyll/update/2018/10/15/GLM.html" rel="alternate" type="text/html" title="From Likelihood Maximization to Loss Minimization" /><published>2018-10-15T13:13:12+08:00</published><updated>2018-10-15T13:13:12+08:00</updated><id>http://localhost:4000/jekyll/update/2018/10/15/GLM</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/15/GLM.html">&lt;p&gt;Loss function is an important component for almost all Machine Learning models, especially neural networks. It compares the &lt;em&gt;prediction&lt;/em&gt; that comes out of the model with the &lt;em&gt;groundtruth&lt;/em&gt;, and determines how dissimilar they are (i.e. how bad the prediction is). For example, a ConvNet-based object detector performs both the &lt;strong&gt;classification&lt;/strong&gt; task and the &lt;strong&gt;regression&lt;/strong&gt; task — it predicts a vector &lt;script type=&quot;math/tex&quot;&gt;p_{cls}&lt;/script&gt; holding the confidence scores corresponding to different object classes, and another vector &lt;script type=&quot;math/tex&quot;&gt;p_{loc}&lt;/script&gt; describing how the anchor boxes should be shifted and scaled so it can tightly bound the object instances. To measure the quality of the predictions, we compute the cross-entropy loss (Sigmoid or Softmax) for classification task, and Huber loss (a variant of squared error loss) for regression task, between the predictions and their respective groundtruths, and we tune the neural network weights to minimize the losses.&lt;/p&gt;

&lt;p&gt;You may wonder why cross-entropy loss and squared-error loss are chosen for classification and regression tasks. In this post I’ll try to justify the choices by providing a probabilistic interpretation of different loss functions. To simplify the disscussion, I’ll use the simplest form of each task — logistic regression and linear regression, as our running examples.&lt;/p&gt;

&lt;h3 id=&quot;problem-setup&quot;&gt;Problem Setup&lt;/h3&gt;

&lt;p&gt;Logistic regression and linear regression are two closely related and well-established techniques in Statistics. They both take as input &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; &lt;strong&gt;observations&lt;/strong&gt;, each represented as a &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;-dimensional row vector, describing different attributes of a given observation (e.g. height and weight of a person). Also, each observation comes with a &lt;strong&gt;label&lt;/strong&gt;, which is discrete-valued (e.g. 1 or 0) for logistic regression, or continuously valued (e.g. 1.8) for linear regression. Formally, the observations are represented as a &lt;script type=&quot;math/tex&quot;&gt;n \times (d + 1)&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt;, and the labels are represented as a column vector &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt;, that is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathbf{X} =
 \begin{pmatrix}
  1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} \\
  1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nd} 
 \end{pmatrix}

=

\begin{pmatrix}
\mathbf{x}_{1}^{T}  \\
\mathbf{x}_{2}^{T}  \\
\vdots \\
\mathbf{x}_{n}^{T}  \\
\end{pmatrix}

\text{,}

\mathbf{y} = 
  \begin{pmatrix}
  y_{1} \\
  y_{2} \\
  \vdots \\
  y_{n}
  \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is the number of observations and &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; is the number of attributes (or features). Note: to accommodate the additional constant &lt;script type=&quot;math/tex&quot;&gt;w_{0}&lt;/script&gt; and to simplify notation (See below), we prefixed the &lt;script type=&quot;math/tex&quot;&gt;n \times d&lt;/script&gt; matrix with a column of ones.&lt;/p&gt;

&lt;p&gt;To generate the predictions, we apply a linear transformation on each observation (i.e. &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}_{i}^{T}&lt;/script&gt;, row of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt;) — a linear combination of attributes plus a constant. Formally, the predicted values are&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{\hat{y}} = 
  \begin{pmatrix}
  \hat{y}_{1} \\
  \hat{y}_{2} \\
  \vdots \\
  \hat{y}_{n}
  \end{pmatrix}
  =
\begin{pmatrix}
    w_{0} + x_{11}w_{1} + x_{12}w_{2} + \cdots + x_{1d}w_{d}\\
    w_{0} + x_{21}w_{1} + x_{22}w_{2} + \cdots + x_{2d}w_{d}\\
    \vdots \\
    w_{0} + x_{n1}w_{1} + x_{n2}w_{2} + \cdots + x_{nd}w_{d} 
  \end{pmatrix} 

= \mathbf{X} \mathbf{w} =
\begin{pmatrix}

\mathbf{x}_{1}^{T} \mathbf{w} \\
\mathbf{x}_{2}^{T} \mathbf{w} \\
\vdots \\
\mathbf{x}_{n}^{T} \mathbf{w} \\

\end{pmatrix}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w} = 
  \begin{pmatrix}
  w_{0} \\
  w_{1} \\
  \vdots \\
  w_{d}
  \end{pmatrix}&lt;/script&gt;

&lt;p&gt;For linear regression, we’ll output the prediction &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\hat{y}}&lt;/script&gt; unchanged. However, for logistic regression, we’ll output an indicator vector, which takes the value of 1 if &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathbf{y}} \ge 0&lt;/script&gt;, and 0 otherwise.&lt;/p&gt;

&lt;h3 id=&quot;model-label-and-observations-as-random-variables&quot;&gt;Model label and observations as random variables&lt;/h3&gt;

&lt;p&gt;The attributes of the observations &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; as well as the labels &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt; are referred to as &lt;em&gt;training data&lt;/em&gt;, and they are &lt;em&gt;fixed&lt;/em&gt; once the process of collecting the training data is finished. However, this process itself may involve certain degree of stochasticity — we may end up collecting a different set of values for &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; if we were to repeat the collecting process; and even if we happen to get the same set of values for &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; as previously collected, the values for the labels &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt; may still be different. As a result, we usually model the labels and observations as &lt;em&gt;random variables&lt;/em&gt;, so &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; are just concrete values that the random variables can take on.&lt;/p&gt;

&lt;p&gt;Formally, given that the training set contains &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; observations with &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; attributes, we use the random variable &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; (&lt;script type=&quot;math/tex&quot;&gt;i= 1, \cdots, n&lt;/script&gt;) to denote the label for the &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;th observation, and random variables &lt;script type=&quot;math/tex&quot;&gt;X_{i1}, X_{i2}, \cdots, X_{id}&lt;/script&gt; to denote its attributes. So &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; takes on the value of each component of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;X_{i1}, X_{i2}, \cdots, X_{id}&lt;/script&gt; take on each row of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/sampling.png&quot; width=&quot;1200&quot; /&gt;
&lt;br /&gt;
Sample a set of data points with observations, and then sample the corresponding labels.
&lt;/p&gt;

&lt;p&gt;Note that the stochasticity associated with the random variables &lt;script type=&quot;math/tex&quot;&gt;X_{i1}, X_{i2}, \cdots, X_{id}&lt;/script&gt; is determined by the distribution of samples in a population — we first sample (randomly) a set of data points according to the distribution, then record their attributes; However, the stochasticity associated with &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; is determined by both the distribution of samples (to determine &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; we first need to sample a data point &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;), and the inevitable error assosicated the labelling the data point &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; (e.g. the measured height may always be slightly different from the true height of an individual). For our discussion, we’ll treat the &lt;script type=&quot;math/tex&quot;&gt;X_{ij}&lt;/script&gt; as fixed, and only discuss &lt;script type=&quot;math/tex&quot;&gt;P(Y_{i} \vert X_{i1}, X_{i2}, \cdots, X_{id})&lt;/script&gt; — the probability of &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; conditioned on &lt;script type=&quot;math/tex&quot;&gt;X_{i1}, X_{i2}, \cdots, X_{id}&lt;/script&gt;, whose randomness is attributed to the labelling error.&lt;/p&gt;

&lt;h3 id=&quot;the-error-distribution&quot;&gt;The error distribution&lt;/h3&gt;
&lt;p&gt;To account for the labelling error, we’ll add an error term &lt;script type=&quot;math/tex&quot;&gt;\epsilon_{i}&lt;/script&gt; to the linear transformation of &lt;script type=&quot;math/tex&quot;&gt;X_{i1}, X_{i2}, \cdots, X_{id}&lt;/script&gt;, and denote the result as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_{i}^{*} = \sum_{j=1}^{d} X_{ij} w_{j} + w_{0} + \epsilon_{i}  \tag{1}&lt;/script&gt;

&lt;p&gt;As discussed previously, for linear regression the label (or the predicted label) &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; is just the linear combination (plus the error), so&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_{i} = Y_{i}^{*}   \tag{2}&lt;/script&gt;

&lt;p&gt;,while for logistic regression, we add a binarization step:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y_{i} = 
\begin{cases} 
  1, \text{    if    } Y_{i}^{*} \ge 0 \\ 
  0, \text{    if    } Y_{i}^{*} \lt 0        \tag{3}
\end{cases}&lt;/script&gt;

&lt;p&gt;As for the error term’s distribution, we assume it  follows a zero-mean &lt;a href=&quot;https://en.wikipedia.org/wiki/Normal_distribution&quot;&gt;normal distribution&lt;/a&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\epsilon_{i} \sim \mathcal{N}(0, \sigma^{2})&lt;/script&gt;

&lt;p&gt;for linear regression, and a &lt;a href=&quot;https://en.wikipedia.org/wiki/Logistic_distribution&quot;&gt;logistic distribution&lt;/a&gt; with location being 0 and scale being 1 for logistic regression.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\epsilon_{i} \sim \text{Logistic}(0, 1)&lt;/script&gt;

&lt;p&gt;We assume that each data point is labelled independently, so &lt;script type=&quot;math/tex&quot;&gt;\epsilon_{i}&lt;/script&gt; and hence &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; should be i.i.d. (independently and identically distributed).&lt;/p&gt;

&lt;h3 id=&quot;maximizing-the-likelihood&quot;&gt;Maximizing the Likelihood&lt;/h3&gt;
&lt;p&gt;Now we are ready to derive the probability of &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; conditioned on &lt;script type=&quot;math/tex&quot;&gt;X_{i1}, X_{i2}, \cdots, X_{id}&lt;/script&gt; analytically, i.e, &lt;script type=&quot;math/tex&quot;&gt;P(Y_{i} = y_{i} \vert X_{i1} = x_{i1}, X_{i2}=x_{i2}, \cdots, X_{id}=x_{id}; \mathbf{w})&lt;/script&gt;. We’ll find the &lt;script type=&quot;math/tex&quot;&gt;\mathbf{w}&lt;/script&gt; that maximizes the logarithm of probability, which is equivalent to maximizing the probability itself.&lt;/p&gt;

&lt;h4 id=&quot;linear-regression&quot;&gt;Linear regression&lt;/h4&gt;
&lt;p&gt;Given equations (1), (2), and &lt;script type=&quot;math/tex&quot;&gt;\epsilon_{i} \sim \mathcal{N}(0, \sigma^{2})&lt;/script&gt;, it follows that &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; is a &lt;strong&gt;continuous&lt;/strong&gt; random variable, and  &lt;script type=&quot;math/tex&quot;&gt;Y_{i} \vert X_{i1}, X_{i2}, \cdots, X_{id} \sim \mathcal{N}(\mathbf{x}_{i}^{T} \mathbf{w}, \sigma^{2})&lt;/script&gt;. Maximizing the log-likelihood, we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
 &amp;\arg\max_{\mathbf{w}} L(\mathbf{w}) \\
= &amp;\arg\max_{\mathbf{w}} \log P(Y_{i} = y_{i} \vert X_{i1} = x_{i1}, X_{i2}=x_{i2}, \cdots, X_{id}=x_{id}; \mathbf{w}) \\ 
= &amp;\arg\max_{\mathbf{w}} \log \frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(y_{i} - \mathbf{x}_{i}^{T} \mathbf{w} )^2}{2\sigma^{2}}} \\ 
= &amp; \arg\max_{\mathbf{w}} \log e^{-\frac{(y_{i} - \mathbf{x}_{i}^{T} \mathbf{w} )^2}{2\sigma^{2}}} \\
= &amp; \arg\min_{\mathbf{w}} (y_{i} - \mathbf{x}_{i}^{T} \mathbf{w} )^2
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;We have just proved that &lt;strong&gt;maximizing the likelihood is equivalent to minimizing the squared error&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;logistic-regression&quot;&gt;Logistic regression&lt;/h4&gt;
&lt;p&gt;Given equations (1) and (3), it follows that &lt;script type=&quot;math/tex&quot;&gt;Y_{i}&lt;/script&gt; is a &lt;strong&gt;discrete&lt;/strong&gt; random variable that takes on the value of 0 or 1, and &lt;script type=&quot;math/tex&quot;&gt;Y_{i} = 1&lt;/script&gt; iff &lt;script type=&quot;math/tex&quot;&gt;Y_{i}^{*} \ge 0&lt;/script&gt;. We have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  &amp; P(Y_{i} = 1 \vert X_{i\cdot} = x_{i\cdot}; \mathbf{w}) \\ 
= &amp; P(Y_{i}^{*} \ge 0 \vert X_{i\cdot} = x_{i\cdot}; \mathbf{w}) \\ 
= &amp; P(\mathbf{x}_{i}^{T} \mathbf{w} + \epsilon_{i} \ge 0 \vert X_{i\cdot} = x_{i\cdot}; \mathbf{w} ) \\
= &amp; P(\epsilon_{i} \ge - \mathbf{x}_{i}^{T} \mathbf{w} \vert X_{i\cdot} = x_{i\cdot}; \mathbf{w}   ) \\ 
= &amp; P(\epsilon_{i} \le \mathbf{x}_{i}^{T} \mathbf{w} \vert X_{i\cdot} = x_{i\cdot}; \mathbf{w}) \\
= &amp; \frac{1}{1 + e^{-\mathbf{x}_{i}^{T} \mathbf{w}}}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;X_{i\cdot} = x_{i\cdot}&lt;/script&gt; denotes &lt;script type=&quot;math/tex&quot;&gt;X_{i1} = x_{i1}, X_{i2}=x_{i2}, \cdots, X_{id}=x_{id}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The last two steps follows from the fact that &lt;script type=&quot;math/tex&quot;&gt;\epsilon_{i} \sim \text{Logistic}(0, 1)&lt;/script&gt;, and its cumulative distribution function is just the logistic function, i.e.  &lt;script type=&quot;math/tex&quot;&gt;P(\epsilon_{i} \le x) = \frac{1}{1 + e^{-x}}&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;P(\epsilon_{i} \gt -x) = 1 - P(\epsilon_{i} \le -x) = 1 - \frac{1}{1 + e^{x}} = \frac{1}{1 + e^{-x}} = P(\epsilon_{i} \le x)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;It follows that &lt;script type=&quot;math/tex&quot;&gt;Y_{i} \vert X_{i1}, X_{i2}, \cdots, X_{id} \sim \text{Bernoulli}(\frac{1}{1 + e^{-\mathbf{x_{i}}^{T} \mathbf{w}}})&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Maximizing the log-likelihood, we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;\arg\max_{\mathbf{w}} L(\mathbf{w})\\
= &amp; \arg\max_{\mathbf{w}} \log P(Y_{i} = y_{i} \vert X_{i1}, X_{i2}, \cdots, X_{id}; \mathbf{w}) \\
= &amp; \arg\max_{\mathbf{w}} \log P(Y_{i} = 1 \vert X_{i1}, X_{i2}, \cdots, X_{id}; \mathbf{w})^{y_{i}} P(Y_{i} = 0 \vert X_{i1}, X_{i2}, \cdots, X_{id}; \mathbf{w})^{1 - y_{i}} \\
= &amp; \arg\max_{\mathbf{w}} y_{i} \log \left( \frac{1}{1 + e^{-\mathbf{x}_{i}^{T} \mathbf{w}}} \right) + (1 - y_{i}) \log \left( 1 - \frac{1}{1 + e^{-\mathbf{x}_{i}^{T} \mathbf{w}}} \right) \\
= &amp; \arg\min_{\mathbf{w}} \left(-y_{i} \log \left( \frac{1}{1 + e^{-\mathbf{x}_{i}^{T} \mathbf{w}}} \right) - (1 - y_{i}) \log \left( 1 - \frac{1}{1 + e^{-\mathbf{x}_{i}^{T} \mathbf{w}}} \right) \right)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Again, we have proved that &lt;strong&gt;maximizing the likelihood is equivalent to minimizing the cross-entropy&lt;/strong&gt;, which is defined between the target distribution (Bernoulli) &lt;script type=&quot;math/tex&quot;&gt;(y_{i}, 1 - y_{i})&lt;/script&gt; and predicted distribution &lt;script type=&quot;math/tex&quot;&gt;(\frac{1}{1 + e^{-\mathbf{x}_{i}^{T} \mathbf{w}}}, 1 - \frac{1}{1 + e^{-\mathbf{x}_{i}^{T} \mathbf{w}}})&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;miminize-the-loss&quot;&gt;Miminize the loss&lt;/h3&gt;
&lt;p&gt;At this point, it’ll be trivial to derive the update algorithm to optimize the losses.&lt;/p&gt;
&lt;h4 id=&quot;linear-regression-1&quot;&gt;Linear regression&lt;/h4&gt;
&lt;p&gt;Let the loss function &lt;script type=&quot;math/tex&quot;&gt;J(\mathbf{w}) = \frac{1}{2} (y_{i} - \mathbf{x}_{i}^{T} \mathbf{w} )^2&lt;/script&gt;. Using chain rule, we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial}{\partial w_{j}} J(\mathbf{w}) = (y_{i} - \mathbf{x}_{i}^{T} \mathbf{w} ) (-x_{ij}) = (\mathbf{x}_{i}^{T} \mathbf{w} - y_{i}) x_{ij}&lt;/script&gt;

&lt;h4 id=&quot;logistic-regression-1&quot;&gt;Logistic regression&lt;/h4&gt;
&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;h(\mathbf{x_{i}^{T}}) = \frac{1}{1 + e^{-\mathbf{x}^{T} \mathbf{w}}}&lt;/script&gt; and the loss function &lt;script type=&quot;math/tex&quot;&gt;J(\mathbf{w}) = -y_{i} \log h(\mathbf{x_{i}^{T}})  - (1 - y_{i}) \log (1 - h(\mathbf{x_{i}^{T}}))&lt;/script&gt;. Using chain rule, we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
  &amp; \frac{\partial}{\partial w_{j}} J(\mathbf{w}) \\
= &amp; \frac{\partial}{\partial w_{j}}  \left(-y_{i} \log h(\mathbf{x_{i}^{T}})  - (1 - y_{i}) \log (1 - h(\mathbf{x_{i}^{T}}))  \right) \\
= &amp; -\frac{y_{i}}{h(\mathbf{x_{i}^{T}})} \frac{\partial}{\partial w_{j}} h(\mathbf{x_{i}^{T}}) + \frac{1 - y_{i}}{ 1 - h(\mathbf{x_{i}^{T}})} \frac{\partial}{\partial w_{j}} h(\mathbf{x_{i}^{T}}) \\
= &amp; \left( \frac{1 - y_{i}}{1 - h(\mathbf{x_{i}^{T}}) } - \frac{y_{i}}{ h(\mathbf{x_{i}^{T}}) } \right) \frac{\partial}{\partial w_{j}} h(\mathbf{x_{i}^{T}}) \\
= &amp; \left( \frac{1 - y_{i}}{1 - h(\mathbf{x_{i}^{T}}) } - \frac{y_{i}}{ h(\mathbf{x_{i}^{T}}) } \right) (1 - h(\mathbf{x_{i}^{T}})) h(\mathbf{x_{i}^{T}}) x_{ij} \\
= &amp;  (h(\mathbf{x_{i}^{T}}) - y_{i}) x_{ij}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;It’s a little surprising that we end up with almost identical update algorithm for both logistic regression and linear regression. In both algorithms, the magnitude of the update depends on the error &lt;script type=&quot;math/tex&quot;&gt;h(\mathbf{x_{i}^{T}}) - y_{i}&lt;/script&gt; or &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}_{i}^{T} \mathbf{w} - y_{i}&lt;/script&gt;, which means if we made a big error in the prediction, we should accordingly make a large stride to update the corredponding weight.&lt;/p&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;p&gt;In this post, we provided a probabilistic interpretation for the principle of loss minimization for linear regression and logistic regression. We discussed the sources of randomness for both labels and inputs, and modeled the labels as random variables conditioned on the observed inputs. We gave assumptions on the probability distributions of the errors, and finally showed that maximizing the likelihood of the labels is equivalent to minimizing the squared error loss or cross entropy loss.&lt;/p&gt;</content><author><name></name></author><summary type="html">Loss function is an important component for almost all Machine Learning models, especially neural networks. It compares the prediction that comes out of the model with the groundtruth, and determines how dissimilar they are (i.e. how bad the prediction is). For example, a ConvNet-based object detector performs both the classification task and the regression task — it predicts a vector holding the confidence scores corresponding to different object classes, and another vector describing how the anchor boxes should be shifted and scaled so it can tightly bound the object instances. To measure the quality of the predictions, we compute the cross-entropy loss (Sigmoid or Softmax) for classification task, and Huber loss (a variant of squared error loss) for regression task, between the predictions and their respective groundtruths, and we tune the neural network weights to minimize the losses.</summary></entry><entry><title type="html">Understanding ROI Align</title><link href="http://localhost:4000/jekyll/update/2018/07/20/ROIAlign.html" rel="alternate" type="text/html" title="Understanding ROI Align" /><published>2018-07-20T15:12:53+08:00</published><updated>2018-07-20T15:12:53+08:00</updated><id>http://localhost:4000/jekyll/update/2018/07/20/ROIAlign</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/07/20/ROIAlign.html">&lt;p&gt;In the &lt;a href=&quot;/_site/jekyll/update/2018/07/19/BilinearResize.html&quot;&gt;previous post&lt;/a&gt; we talked about bilinear interpolation algorithm. In this post we’ll see its application in &lt;strong&gt;ROI Align&lt;/strong&gt;, which is a technique based on bilinear interpolation to &lt;em&gt;smoothly&lt;/em&gt; crop a patch from a full-image feature map based on a region proposal, and then resize the cropped patch to a desired spatial size. It was introduced in the Mask R-CNN model, and has been shown to outperform the alternative that does “harsh crop” (i.e. ROI Pooling).&lt;/p&gt;

&lt;p&gt;We’ll discuss the main idea of ROI Align and provide numpy implementation. In addition, we’ll discuss how to compute its backward pass when we train a neural network that uses ROI Align.&lt;/p&gt;

&lt;h3 id=&quot;roi-align&quot;&gt;ROI Align&lt;/h3&gt;

&lt;p&gt;ROI Align takes as input&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a feature map (e.g. 2-D array)&lt;/li&gt;
  &lt;li&gt;a bounding box corresponding to a region proposal. The bounding box is represented by its coordinates &lt;code class=&quot;highlighter-rouge&quot;&gt;y_min&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;x_min&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;y_max&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;x_max&lt;/code&gt;, where &lt;code class=&quot;highlighter-rouge&quot;&gt;0 &amp;lt;= y_min &amp;lt; y_max &amp;lt;= 1&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;0 &amp;lt;= x_min &amp;lt; x_max &amp;lt;= 1&lt;/code&gt;. Note that the coordinates are normalized and denote the &lt;em&gt;relative&lt;/em&gt; position w.r.t. the spatial size of the input feature map.&lt;/li&gt;
  &lt;li&gt;the desired height and width of the output feature map (e.g. height=3, width=3)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Given the 5x5 feature map and the red bounding box shown below, ROI Align outputs a 3x3 feature map computed from the values bounded within the red box.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/bilinear_interpolation/feature_map.png&quot; width=&quot;400&quot; /&gt;
&lt;br /&gt; ROI Align crops a patch whose edges may not align with cell boundaries.
&lt;/p&gt;

&lt;p&gt;You may wonder how we should deal with values that are &lt;em&gt;partially&lt;/em&gt; shared by the cells in the red grid, since the black edges are not necessarily aligned with red edges. Actually I was very confused at the beginning when I tried to understand ROI Align, but then I realized that it may be better to think of the cells in the black and red grid as points in 2-D array, as shown below:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/bilinear_interpolation/dots.png&quot; width=&quot;400&quot; /&gt;
&lt;br /&gt; Black dots: cells in input feature map; Red dots: cells in output feature map.
&lt;/p&gt;

&lt;p&gt;First we need to map the coordinates of red points that vary in &lt;script type=&quot;math/tex&quot;&gt;[0.0, 1.0]&lt;/script&gt; to coordinates that vary in &lt;script type=&quot;math/tex&quot;&gt;[0.0, 4.0]&lt;/script&gt;. For example, a red point with coordinate &lt;script type=&quot;math/tex&quot;&gt;(0.3, 0.5)&lt;/script&gt; is mapped to coordinate &lt;script type=&quot;math/tex&quot;&gt;(1.2, 2.0)&lt;/script&gt;. Next, we compute the interpolated values of the red point based on the values of the four black points closest to it, which is exactly the bilinear interpolation problem.&lt;/p&gt;

&lt;h3 id=&quot;the-algorithm&quot;&gt;The Algorithm&lt;/h3&gt;

&lt;p&gt;As we have seen, the cells in the output feature map are represented as evenly-spaced points in 2-D space (red points in the figure above), so first we need to compute their coordinates. And because the coordinates of the bounding box are relative, we also need to convert them to absolute coordinates:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;y_coordinates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_coordinates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;img_height&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;img_width&lt;/code&gt; are height and width of input feature map, and &lt;code class=&quot;highlighter-rouge&quot;&gt;height&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;width&lt;/code&gt; are the desired height and width of output feature map.&lt;/p&gt;

&lt;p&gt;Given the coordinate (may be fractional) &lt;code class=&quot;highlighter-rouge&quot;&gt;[y, x]&lt;/code&gt; of a red point, we can find the coordinate of the upper left, upper right, lower left, lower right neighbor: &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_l, x_l]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_l, x_h]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_h, x_l]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_h, x_h]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Putting together, we have the algorithm for ROI align:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;roi_align&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  `image` is a 2-D array, representing the input feature map
  `box` is a list of four numbers
  `height` and `width` are the desired spatial size of output feature map
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;feature_map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
            &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
            &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;feature_map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We verify the correctness of our implementation by comparing it with the reference implementation. Actually the function &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.image.crop_and_resize&lt;/code&gt; implements ROI align.&lt;/p&gt;

&lt;p&gt;Given a 5x6 input feature map&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;251.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;44.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;47.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;104.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;178.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;101.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;93.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;46.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;73.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;218.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;192.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;22.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;98.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;85.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;122.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;144.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;172.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;151.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;227.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;22.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;58.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;27.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;144.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;160.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;64.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;77.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;192.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;18.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;253.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;31.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and bounding box&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.43&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;we generate the output feature map of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;[3, 2]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Our implementation returns&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;85.03&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;164.112&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;88.&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;155.95&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;90.97&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;147.788&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;which is the same as what is returned by &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.image.crop_and_resize&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;vectorized-version&quot;&gt;Vectorized Version&lt;/h4&gt;

&lt;p&gt;Again, we should make our implementation free of python for loops by taking advantage of numpy’s vectorized operation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;roi_align_vectorized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  `image` is a 2-D array, representing the input feature map
  `box` is a list of four numbers
  `height` and `width` are the desired spatial size of output feature map
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meshgrid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;feature_map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feature_map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;backward-pass-of-roi-align&quot;&gt;Backward Pass of ROI Align&lt;/h3&gt;

&lt;p&gt;As in the backward pass of Bilinear Resizing, we need to properly route the gradient w.r.t. &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt; to a subset of entries in the input &lt;code class=&quot;highlighter-rouge&quot;&gt;image&lt;/code&gt;. And again, the backward pass of ROI Align does not need to use the value of the forward pass.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;roi_align_vectorized_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  `image` is a 2-D array, representing the input feature map
  `box` is a list of four numbers
  `height` and `width` are the desired spatial size of output feature map
  `grad` is a 2-D array of shape [height, width], holding gradient backpropped
    from downstream layer. 
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;
  
  &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meshgrid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# gradient wrt `a`, `b`, `c`, `d`
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# [4 * height * width]
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# [4 * height * width]
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# we must route gradients in `grad` to the correct indices of `image` in 
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# `indices`
&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# use numpy's broadcasting rule to generate 2-D array of shape
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [4 * height * width, img_height * img_width] 
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_along_axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We use some test case to verify the correctness of the backward pass:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enable_eager_execution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientTape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_to_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.43&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;crop_and_resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grad_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grad_tf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;roi_align_vectorized_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# compare if `grad_tf` and `grad` are equal.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">In the previous post we talked about bilinear interpolation algorithm. In this post we’ll see its application in ROI Align, which is a technique based on bilinear interpolation to smoothly crop a patch from a full-image feature map based on a region proposal, and then resize the cropped patch to a desired spatial size. It was introduced in the Mask R-CNN model, and has been shown to outperform the alternative that does “harsh crop” (i.e. ROI Pooling).</summary></entry><entry><title type="html">Understanding Bilinear Image Resizing</title><link href="http://localhost:4000/jekyll/update/2018/07/19/BilinearResize.html" rel="alternate" type="text/html" title="Understanding Bilinear Image Resizing" /><published>2018-07-19T00:09:32+08:00</published><updated>2018-07-19T00:09:32+08:00</updated><id>http://localhost:4000/jekyll/update/2018/07/19/BilinearResize</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/07/19/BilinearResize.html">&lt;p&gt;Resizing an image (or a feature map) to a desired spatial dimension is a common operation when building computer vision applications based on convolutional neural networks. For example, some semantic segmentation models (like FCN or DeepLab) generate a feature map with a large stride S (i.e. height and width of the feature map is 1/S of that of the image, where S = 16 or 32), which must be resized back to the exact spatial dimension of the original image to provide pixelwise prediction.&lt;/p&gt;

&lt;p&gt;Bilinear interpolation is an intuitive algorithm for image resizing. It is a generalization of linear interpolation which only works on 1-D array. In this post, we will discuss the intuition behind interplation algorithms (linear or bilinear), and provide numpy implementations so you will understand exactly how they work. We will also investigate how to compute the &lt;strong&gt;backward&lt;/strong&gt; pass of bilinear resizing when we train a neural network which uses this operation.&lt;/p&gt;

&lt;h3 id=&quot;linear-interpolation&quot;&gt;Linear Interpolation&lt;/h3&gt;
&lt;p&gt;We will first discuss Linear Interpolation which is more common and easier to understand.&lt;/p&gt;

&lt;p&gt;Let’s say we have two points on a straight line with coordinate &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;, and they are associated with values &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;B&lt;/script&gt;. Now if we have a third point with coordinate &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;a \le x \le b&lt;/script&gt;, how do we interpolate the values of cooridnates &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; at coordinate &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;?&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/bilinear_interpolation/linear_interpolation.png&quot; width=&quot;400&quot; /&gt;
&lt;br /&gt;
Linear Interpolation between two ponits.
&lt;/p&gt;

&lt;p&gt;The Linear Interpolation computes it as a &lt;em&gt;weighted average&lt;/em&gt; of the values associated with the two points, where the weights are proportional to the distance between &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X = A \frac{b-x}{b-a} + B \frac{x-a}{b-a}&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X = A (1 - w) + B w&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;w = \frac{x - a}{b - a}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The weight for &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; is proportional to &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;’s distance to &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; (rather than &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;), while the weight for &lt;script type=&quot;math/tex&quot;&gt;B&lt;/script&gt; is proportional to its distnace to &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; (rather than &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;). When &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; moves to &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;, its value &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; becomes &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt;; similarly, &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; becomes &lt;script type=&quot;math/tex&quot;&gt;B&lt;/script&gt; when &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; moves to &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;linearly-resize-1-d-array&quot;&gt;Linearly Resize 1-D Array&lt;/h4&gt;
&lt;p&gt;Given that we know how to do interpolation between two points, let’s consider a more general scenario: we have a 1-D array &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; of size &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt; (e.g &lt;code class=&quot;highlighter-rouge&quot;&gt;n = 5&lt;/code&gt; ), and we wish to stretch or shrink the array to a differet size &lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt; (e.g &lt;code class=&quot;highlighter-rouge&quot;&gt;m = 4&lt;/code&gt;), where the values in the new array &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; is somehow computed from the original array in a linear fashion.&lt;/p&gt;

&lt;p&gt;Image we place the &lt;code class=&quot;highlighter-rouge&quot;&gt;n = 5&lt;/code&gt; points on a straight line, where they are spaced by a distance of 1.0. Now image there is another straight line that runs parallel to it, where we place the points of the new array. Note that we make the coordinates of the first and last element of the new array the same as their counterparts in the orignal array (i.e. 0.0 and 4.0).&lt;/p&gt;

&lt;p&gt;How do we get the values of array &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;? Well, it makes sense to let &lt;code class=&quot;highlighter-rouge&quot;&gt;b[0] == a[0]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b[3] == a[4]&lt;/code&gt;, because they have the same coordinates. For those points in the new array for which we don’t have corresponding points in the original array (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;b[1]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b[2]&lt;/code&gt;), we can map them to the original array where they will have fractionally-valued coordinates (&lt;code class=&quot;highlighter-rouge&quot;&gt;4/3&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;8/3&lt;/code&gt;). Then &lt;code class=&quot;highlighter-rouge&quot;&gt;b[4/3]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;b[8/3]&lt;/code&gt; can be computed using the Linear Interpolation approach from &lt;code class=&quot;highlighter-rouge&quot;&gt;a[1]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;a[2]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;a[2]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;a[3]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now the question reduces to how do we map the coordinates from the new array &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; to the original array &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;. We notice that the mapping depends on the ratio of the length of “integer intervals” — in this case, it’s &lt;code class=&quot;highlighter-rouge&quot;&gt;4/3&lt;/code&gt; (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;(n - 1)/(m - 1)&lt;/code&gt;). For element in array &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt; with index &lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;, its mapped coordinate in array &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;ratio * i&lt;/code&gt;, and we compute the interpolation using the values of the two neighboring elements &lt;code class=&quot;highlighter-rouge&quot;&gt;a[floor(ratio * i)]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;a[ceil(ratio * i)]&lt;/code&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/bilinear_interpolation/linear_resize.png&quot; width=&quot;400&quot; /&gt;
&lt;br /&gt;
Resize 1-D array.
&lt;/p&gt;

&lt;p&gt;Putting together, we have the algorithm for linearly resizing 1-D array:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;
  
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear_resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  `in_array` is the input array.
  `size` is the desired size.
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;out_array&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;out_array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_array&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;bilinear-interpolation&quot;&gt;Bilinear Interpolation&lt;/h3&gt;

&lt;p&gt;Like linearly resizing a 1-D array, bilinearly resizing a 2-D array relies on bilinear interpolation, which can be broken down into linear resizing operations in &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; (height) and &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; (width) dimension. Suppose we have four points with coordinates &lt;script type=&quot;math/tex&quot;&gt;(y_{1}, x_{1})&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;(y_{1}, x_{2})&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;(y_{2}, x_{1})&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;(y_{2}, x_{2})&lt;/script&gt; and associated valued &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;B&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/bilinear_interpolation/bilinear_resize.png&quot; width=&quot;400&quot; /&gt;
&lt;br /&gt;
Bilinear interpolation between four points.
&lt;/p&gt;

&lt;p&gt;We first compute the interpolated value of &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; in the width dimension,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X = A(1-w_{x}) + B w_{x}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y = C(1-w_{x}) + D w_{x}&lt;/script&gt;

&lt;p&gt;Then we will do linear interpolation between the two interpolated values &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; in the height dimension,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
Z &amp; = X(1-w_{y}) + Y w_{y} \\
  &amp; = A(1 - w_{x})(1-w_{y}) + B w_{x} (1 - y_{y}) + C (1 - w_{x}) w_{y} + D w_{x} w_{y} \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;w_{x} = \frac{x - x_{1}}{x_{2} - x_{1}}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;w_{y} = \frac{y - y_{1}}{y_{2} - y_{1}}&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;bilinearly-resize-2-d-array&quot;&gt;Bilinearly Resize 2-D Array&lt;/h4&gt;

&lt;p&gt;Bilinearly resizing a 2-D array is very much like linearly resizing a 1-D array. We first need to find the ratios (now in two dimensions),&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;ratio_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ratio_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;height&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;width&lt;/code&gt; are the dimensions of the new 2-D array.&lt;/p&gt;

&lt;p&gt;Suppose we wish to compute the interpolated value for the point at coordinate &lt;code class=&quot;highlighter-rouge&quot;&gt;[i, j]&lt;/code&gt; where &lt;code class=&quot;highlighter-rouge&quot;&gt;0 &amp;lt;= i &amp;lt; height&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;0 &amp;lt;= j &amp;lt; width&lt;/code&gt;. Its mapped coordinate in the original 2-D array is computed as &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_ratio * i, x_ratio * j]&lt;/code&gt;. Then the coordinates of the four points that are closest to &lt;code class=&quot;highlighter-rouge&quot;&gt;[i, j]&lt;/code&gt; are &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_l, x_l]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_l, x_h]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_h, x_l]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;[y_h, x_h]&lt;/code&gt;, where&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Putting together, we have the algorithm for bilinearly resizing 2-D array:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;math&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bilinear_resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  `image` is a 2-D numpy array
  `height` and `width` are the desired spatial dimension of the new 2-D array.
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;resized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;pixel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; \ 
              &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;

      &lt;span class=&quot;n&quot;&gt;resized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resized&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We verify the correctness of our implementation by comparing it with the reference implementation in tensorflow.&lt;/p&gt;

&lt;p&gt;First we need to create a 2-D array populated with random values:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;114.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;195.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;254.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;217.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;33.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;160.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;110.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;91.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;184.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;143.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;190.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;124.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;212.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;163.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;245.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;39.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;83.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;188.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;23.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;206.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;62.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;7.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;5.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;206.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;152.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;177.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;118.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;155.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;245.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;41.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and we will resize it into a 2-D array with 2 rows and 10 columns.&lt;/p&gt;

&lt;p&gt;Our implementation returns&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;114.&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;159.&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;201.55556&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;234.33333&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;245.77777&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;mf&quot;&gt;225.22223&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;155.66667&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;53.444443&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;89.44444&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;160.&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;152.&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;165.88889&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;170.44444&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;137.66667&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;126.22222&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;mf&quot;&gt;146.77777&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;185.&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;235.&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;154.33333&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;41.&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which is the same as the output of &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.image.resize_images(tf.expand_dims(image, axis=2), [2, 10], align_corners=True)&lt;/code&gt; (up to the numerical precision).&lt;/p&gt;

&lt;p&gt;Finally, let’s test out our implementation to resize a real image&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/bilinear_interpolation/original.png&quot; width=&quot;387&quot; /&gt; &lt;img src=&quot;/assets/bilinear_interpolation/resized.png&quot; width=&quot;250&quot; /&gt;
&lt;br /&gt;
Left: Original image of size 425 by 775. Right: Resized image of size 500 by 500.
&lt;/p&gt;

&lt;h4 id=&quot;vectorized-version&quot;&gt;Vectorized Version&lt;/h4&gt;

&lt;p&gt;NOTE: The function &lt;code class=&quot;highlighter-rouge&quot;&gt;bilinear_resize&lt;/code&gt; uses python for loop, which runs very slow. We can take advantage of numpy’s vectorized computation on arrays to speed it up.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bilinear_resize_vectorized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  `image` is a 2-D numpy array
  `height` and `width` are the desired spatial dimension of the new 2-D array.
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;divmod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;resized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
            &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
            &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;backward-pass-of-bilinear-resizing&quot;&gt;Backward Pass of Bilinear Resizing&lt;/h3&gt;
&lt;p&gt;Remember that bilinear resizing is essentially a &lt;em&gt;function&lt;/em&gt; where the input is a 2-D array of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;[img_height, img_width]&lt;/code&gt; and output is a 2-D array of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;[height, width]&lt;/code&gt;. When doing backpropagation, we take as input the gradient &lt;code class=&quot;highlighter-rouge&quot;&gt;grad&lt;/code&gt; backpropped from the downstream layer — a 2-D array of the same shape as the output (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;[heigth, width]&lt;/code&gt;), and we compute the gradient of shape &lt;code class=&quot;highlighter-rouge&quot;&gt;[img_height, img_width]&lt;/code&gt; to be backpropped to its upstream layer.&lt;/p&gt;

&lt;p&gt;Note that in the forward pass (&lt;code class=&quot;highlighter-rouge&quot;&gt;bilinear_resize_vectorized&lt;/code&gt;) we computed the output — resized image — as a linear combination of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt;, each of which corresponds to a &lt;em&gt;subset&lt;/em&gt; of entries of the input &lt;code class=&quot;highlighter-rouge&quot;&gt;image&lt;/code&gt;. The gradient w.r.t to &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;d&lt;/code&gt; are simply their coeffients, &lt;code class=&quot;highlighter-rouge&quot;&gt;(1 - x_weight) * (1 - y_weight)&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;x_weight * (1 - y_weight)&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;y_weight * (1 - x_weight)&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;x_weight * y_weight&lt;/code&gt;, multiplied by &lt;code class=&quot;highlighter-rouge&quot;&gt;grad&lt;/code&gt;, and they must be properly &lt;em&gt;routed&lt;/em&gt; to the corresponding entries in the input &lt;code class=&quot;highlighter-rouge&quot;&gt;image&lt;/code&gt;. Detailed implementation are as below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bilinear_resize_vectorized_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  `image` is a 2-D array, holding the input image
  `height` and `width` are the desired spatial dimension of the new 2-D array. 
  `grad` is a 2-D array of shape [height, width], holding the gradient to be
    backpropped to `image`.
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;divmod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# gradient wrt `a`, `b`, `c`, `d`
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# [4 * height * width]
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# [4 * height * width]
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;y_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# we must route gradients in `grad` to the correct indices of `image` in 
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# `indices`, e.g. only entries of indices `y_l * img_width + x_l` in `image`
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# gets the gradient backpropped from `a`.
&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# use numpy's broadcasting rule to generate 2-D array of shape
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [4 * height * width, img_height * img_width]
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;d_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_along_axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;As we can see, when computing the backward pass of bilinear resizing we do not need to store the value of the forward pass.&lt;/p&gt;

&lt;p&gt;Finally, we verify the correctness of the backward pass using some test case:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enable_eager_execution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientTape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_to_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;align_corners&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grad_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grad_tf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_gradients&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad_val&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bilinear_resize_vectorized_backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# compare if `grad_tf` and `grad` are equal.
&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">Resizing an image (or a feature map) to a desired spatial dimension is a common operation when building computer vision applications based on convolutional neural networks. For example, some semantic segmentation models (like FCN or DeepLab) generate a feature map with a large stride S (i.e. height and width of the feature map is 1/S of that of the image, where S = 16 or 32), which must be resized back to the exact spatial dimension of the original image to provide pixelwise prediction.</summary></entry><entry><title type="html">SVD Explained</title><link href="http://localhost:4000/jekyll/update/2016/03/10/SVD.html" rel="alternate" type="text/html" title="SVD Explained" /><published>2016-03-10T23:42:01+08:00</published><updated>2016-03-10T23:42:01+08:00</updated><id>http://localhost:4000/jekyll/update/2016/03/10/SVD</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2016/03/10/SVD.html">&lt;p&gt;In the previous post we talked about &lt;strong&gt;Principlal Component Analysis&lt;/strong&gt;, a popular statistical technique for dimensionality reduction and feature decorrelation. Another common use case is matrix decomposition, where a matrix is factorized into a product of matrices (Eigendecomposition).&lt;/p&gt;

&lt;p&gt;A limitation of Eigendecomposition is that it only works on &lt;em&gt;square&lt;/em&gt; matrices. &lt;strong&gt;Singular Value Decomposition&lt;/strong&gt; (SVD) is a generalization of Eigendecomposition, which works on any rectangle-shaped matrix. It has been widely used in Machine Learning applications such as &lt;a href=&quot;https://en.wikipedia.org/wiki/Latent_semantic_analysis&quot;&gt;Latent Semantic Analysis&lt;/a&gt; (LSA), where a document-word matrix is decomposed and re-represented while keeping the pattern in the original matrix, and image compression, where a matrix holding the pixel intensities is decomposed and re-represented as the product of three much smaller matrices, from which the original image can be reconstructed.&lt;/p&gt;

&lt;p&gt;In this post, I’ll explain mathematically why a Singular Value Decomposition always exists for any rectangle-shaped matrix, and how to find it. It is assumed that you have some basic grasp of Linear Algebra (I recommend you to read the post on PCA).&lt;/p&gt;

&lt;h2 id=&quot;the-math&quot;&gt;The Math&lt;/h2&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; be any &lt;script type=&quot;math/tex&quot;&gt;m \times n&lt;/script&gt; real-valued matrix where &lt;script type=&quot;math/tex&quot;&gt;m \le n&lt;/script&gt;. It can be shown that the &lt;script type=&quot;math/tex&quot;&gt;m \times m&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;AA^{T}&lt;/script&gt; is&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;symmetric&lt;/li&gt;
  &lt;li&gt;positive semidefinite&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1}, \lambda_{2}, \cdots, \lambda_{m}&lt;/script&gt; be the &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; eigenvalues of &lt;script type=&quot;math/tex&quot;&gt;AA^{T}&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;u_{1}, u_{2}, \cdots, u_{m}&lt;/script&gt; be the eigenvectors (column vectors of shape &lt;script type=&quot;math/tex&quot;&gt;m \times 1&lt;/script&gt;) corresponding to &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1}, \lambda_{2}, \cdots, \lambda_{m}&lt;/script&gt;, respectively. It follows that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
AA^{T}u_{1} &amp;= \lambda_{1} u_{1} \\
AA^{T}u_{2} &amp;= \lambda_{2} u_{2} \\
&amp;\cdots \\
AA^{T}u_{m} &amp; = \lambda_{m} u_{m} \\
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The eigenvalues are non-negative: &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1} \ge 0, \lambda_{2} \ge 0, \cdots, \lambda_{m} \ge 0&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;The eigenvectors (corresponding to different eigenvalues) are pairwise orthogonal: &lt;script type=&quot;math/tex&quot;&gt;u_{i}^{T}u_{j} = 0&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i \ne j&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;i, j = 1, \cdots, m&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ll further assume that &lt;script type=&quot;math/tex&quot;&gt;u_{1}, u_{2}, \cdots, u_{m}&lt;/script&gt; are unit vectors:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;u_{i}^{T}u_{i} = 1&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Let’s define another &lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; column vectors &lt;script type=&quot;math/tex&quot;&gt;v_{i}&lt;/script&gt; (of shape &lt;script type=&quot;math/tex&quot;&gt;n \times 1&lt;/script&gt;):&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;v_{i} = \frac{1}{\sqrt{\lambda_{i}}} A^{T}u_{i}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can show that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
A^{T}Av_{i} &amp; = A^{T}A \frac{1}{\sqrt{\lambda_{i}}} A^{T} u_{i} = \frac{1}{\sqrt{\lambda_{i}}} A^{T} A A^{T} u_{i} \\ 
            &amp;= \frac{1}{\sqrt{\lambda_{i}}} A^{T} \lambda_{i} u_{i} = \sqrt{\lambda_{i}} A^{T} u_{i} = \sqrt{\lambda_{i}} \sqrt{\lambda_{i}} v_{i} = \lambda_{i} v_{i}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;In other words, &lt;script type=&quot;math/tex&quot;&gt;\lambda_{i}&lt;/script&gt;’s are also eigenvalues of the &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; of matrix &lt;script type=&quot;math/tex&quot;&gt;A^{T}A&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;v_{i}&lt;/script&gt;’s are the eigenvectors corresponding to &lt;script type=&quot;math/tex&quot;&gt;\lambda_{i}&lt;/script&gt;, for &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;and &lt;script type=&quot;math/tex&quot;&gt;v_{i}&lt;/script&gt;’s are unit vectors too:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
v_{i}^{T}v_{i} &amp; = \frac{1}{\sqrt{\lambda_{i}}} u_{i}^{T} A \cdot \frac{1}{\sqrt{\lambda_{i}}} A^{T}u_{i} \\
               &amp; = \frac{1}{\lambda_{i}} u_{i}^{T} A A^{T} u_{i} = \frac{1}{\lambda_{i}} u_{i}^{T} \lambda_{i} u_{i} = u_{i}^{T} u_{i} = 1
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Note that &lt;script type=&quot;math/tex&quot;&gt;A^{T} A&lt;/script&gt; is a &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; matrix and &lt;script type=&quot;math/tex&quot;&gt;n \ge m&lt;/script&gt;, so it might have additional eigenvalues &lt;script type=&quot;math/tex&quot;&gt;\lambda_{m + 1}, \lambda_{m + 2}, \cdots, \lambda_{n}&lt;/script&gt;, with the corresponding eigenvectors &lt;script type=&quot;math/tex&quot;&gt;v_{m+1}, v_{m+2}, \cdots, v_{n}&lt;/script&gt;, respectively. Because the eigenvectors &lt;script type=&quot;math/tex&quot;&gt;v_{1}, v_{2}, \cdots, v_{m}, v_{m+1}, \cdots, v_{n}&lt;/script&gt; correspond to different eigenvalues, they must be pairwise orthogonal:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;v_{i}^{T}v_{j} = 0&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i \ne j&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;i, j = 1, \cdots, n&lt;/script&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Finally, let’s put together the two groups of eigenvectors into a &lt;script type=&quot;math/tex&quot;&gt;m \times m&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; and a &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt;, where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;U = \begin{bmatrix}u_{1}^{T}\\u_{2}^{T} \\ \vdots \\ u_{m}^{T}\end{bmatrix}&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
V = \begin{bmatrix} v_{1} &amp; v_{2} &amp; \cdots &amp; v_{m} &amp; v_{m+1} &amp; \cdots&amp; v_{n} \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Note that both &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; are inversible because their rows/columns are pairwise orthogonal (hence linearly independent).&lt;/p&gt;

&lt;p&gt;Let’s compute the product of three matrices &lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
U A V &amp; = \begin{bmatrix}u_{1}^{T}\\u_{2}^{T} \\ \vdots \\ u_{m}^{T}\end{bmatrix} \cdot A \cdot \begin{bmatrix} v_{1} &amp; v_{2} &amp; \cdots &amp; v_{m} &amp; v_{m+1} &amp; \cdots&amp; v_{n} \end{bmatrix} \\
  &amp; = \begin{bmatrix} u_{1}^{T}A \\ u_{2}^{T}A \\ \vdots \\ u_{m}^{T}A\end{bmatrix} \cdot \begin{bmatrix}v_{1} &amp; v_{2} &amp; \cdots &amp; v_{m} &amp; v_{m + 1} &amp; \cdots &amp; v_{n} \end{bmatrix} \\
 &amp; = \begin{bmatrix}
  u_{1}^{T}Av_{1} &amp; u_{1}^{T}Av_{2} &amp; \cdots &amp; u_{1}^{T}Av_{m} &amp; u_{1}^{T}Av_{m+1} &amp; \cdots &amp; u_{1}^{T}Av_{n} \\
  u_{2}^{T}Av_{1} &amp; u_{2}^{T}Av_{2} &amp; \cdots &amp; u_{2}^{T}Av_{m} &amp; u_{2}^{T}Av_{m+1} &amp; \cdots &amp; u_{2}^{T}Av_{n} \\
  \vdots &amp; \vdots &amp; &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\
  u_{m}^{T}Av_{1} &amp; u_{m}^{T}Av_{2} &amp; \cdots &amp; u_{m}^{T}Av_{m} &amp; u_{m}^{T}Av_{m+1} &amp; \cdots &amp; u_{m}^{T}Av_{n} 
  \end{bmatrix} 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Remember that we defined &lt;script type=&quot;math/tex&quot;&gt;v_{i} = \frac{1}{\sqrt{\lambda_{i}}} A^{T}u_{i}&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;It follows that &lt;script type=&quot;math/tex&quot;&gt;u_{i}^{T} A = \sqrt{\lambda_{i}} v_{i}^{T}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Therefore for &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;j = 1, \cdots, n&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
u_{i}^{T} A v_{j} = \sqrt{\lambda_{i}} v_{i}^{T} v_{j} = \begin{cases}
  \sqrt{\lambda_{i}}, &amp; 1 \le i = j \le m \\
  0, &amp; i \ne j
\end{cases} %]]&gt;&lt;/script&gt;

&lt;p&gt;So&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
UAV = 
\begin{bmatrix} 
  \sqrt{\lambda_{1}} &amp;  &amp; \cdots &amp;  &amp; &amp; \cdots &amp; \\
  &amp; \sqrt{\lambda_{2}} &amp; \cdots &amp; &amp; &amp; \cdots &amp; \\
  \vdots &amp; \vdots &amp; &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\
  &amp; &amp; \cdots &amp; \sqrt{\lambda_{m}} &amp; &amp; \cdots &amp;  
\end{bmatrix}
= \Sigma %]]&gt;&lt;/script&gt;

&lt;p&gt;and the SVD of A is 
&lt;script type=&quot;math/tex&quot;&gt;A = U^{-1} \Sigma V^{-1}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Recap&lt;/strong&gt;: the following are the steps to carry out SVD on any rectangle-shaped matrix &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; of shape &lt;script type=&quot;math/tex&quot;&gt;m \times n&lt;/script&gt; (&lt;script type=&quot;math/tex&quot;&gt;m \le n&lt;/script&gt;)&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Compute &lt;script type=&quot;math/tex&quot;&gt;A A^{T}&lt;/script&gt; and find its eigenvalues &lt;script type=&quot;math/tex&quot;&gt;\lambda_{i}&lt;/script&gt; and eigenvectors &lt;script type=&quot;math/tex&quot;&gt;u_{i}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;Build &lt;script type=&quot;math/tex&quot;&gt;m \times m&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;U = \begin{bmatrix}u_{1}^{T}\\u_{2}^{T} \\ \vdots \\ u_{m}^{T}\end{bmatrix}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Build &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
V = \begin{bmatrix} v_{1} &amp; v_{2} &amp; \cdots &amp; v_{m} &amp; v_{m+1} &amp; \cdots&amp; v_{n} \end{bmatrix} %]]&gt;&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;v_{i} = \frac{1}{\sqrt{\lambda_{i}}} A^{T}u_{i}&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;i = 1, \cdots, m&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;v_{m + 1}, \cdots, v_{n}&lt;/script&gt; are eigenvectors of &lt;script type=&quot;math/tex&quot;&gt;A^{T}A&lt;/script&gt; corresponding to eigenvalues &lt;script type=&quot;math/tex&quot;&gt;\lambda_{m + 1}, \cdots, \lambda_{n}&lt;/script&gt; that are not eigenvalues of &lt;script type=&quot;math/tex&quot;&gt;AA^{T}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Build matrix &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{bmatrix}
  \sqrt{\lambda_{1}} &amp;  &amp; \cdots &amp;  &amp; &amp; \cdots &amp; \\
  &amp; \sqrt{\lambda_{2}} &amp; \cdots &amp; &amp; &amp; \cdots &amp; \\
  \vdots &amp; \vdots &amp; &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\
  &amp; &amp; \cdots &amp; \sqrt{\lambda_{m}} &amp; &amp; \cdots &amp;  
\end{bmatrix} %]]&gt;&lt;/script&gt; of shape &lt;script type=&quot;math/tex&quot;&gt;n \times m&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Compute &lt;script type=&quot;math/tex&quot;&gt;A_{SVD} = U^{-1} \Sigma V^{-1}&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;h3 id=&quot;toy-example&quot;&gt;Toy example&lt;/h3&gt;
&lt;p&gt;First let’s create a small matrix that is easy to test out the theory:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# w must be &amp;gt;= h 
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Find the eigenvalues and eigenvectors of &lt;code class=&quot;highlighter-rouge&quot;&gt;A.dot(A.T)&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;A.T.dot(A)&lt;/code&gt;, respectively:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;n&quot;&gt;eigval1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvec1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eigval2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvec2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Build the matrix &lt;code class=&quot;highlighter-rouge&quot;&gt;U&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;V&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvec1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Note: we use `thres` to determine which eigenvalues of `A.T.dot(A)` 
# are NOT eigenvalues of `A.dot(A.T)`
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thres&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigval2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigval1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thres&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigvec1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigval1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
               &lt;span class=&quot;n&quot;&gt;eigvec2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Build the matrix &lt;code class=&quot;highlighter-rouge&quot;&gt;Sigma&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigval1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Finaly compute &lt;code class=&quot;highlighter-rouge&quot;&gt;A_SVD&lt;/code&gt; (Note &lt;code class=&quot;highlighter-rouge&quot;&gt;U&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;V&lt;/code&gt; are &lt;a href=&quot;https://en.wikipedia.org/wiki/Orthogonal_matrix&quot;&gt;orthonormal&lt;/a&gt; matrices so their inverses are identical to their transposed forms):&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;A_SVD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;You can see that the reconstructed matrix is identical to the original (up to the error in numerical precision):&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;199.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;227.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;237.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;107.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;120.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;254.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;116.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;184.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;220.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;171.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;212.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;150.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;85.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;195.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;83.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;24.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;51.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;178.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;205.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;135.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_SVD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;199.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;227.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;237.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;107.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;120.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;254.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;116.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;184.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;220.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;171.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;212.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;150.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;85.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;195.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;83.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
       &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;24.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;51.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;178.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;205.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;135.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;image-compression&quot;&gt;Image compression&lt;/h3&gt;

&lt;p&gt;There is much neater way to carry out SVD than the above precedure. You can use the built-in function of NumPy in one line of code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;svd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The matrices &lt;code class=&quot;highlighter-rouge&quot;&gt;u&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;vh&lt;/code&gt; are like &lt;code class=&quot;highlighter-rouge&quot;&gt;U.T&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;V.T&lt;/code&gt; as the above example, and &lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt; is a 1-D array holding the &lt;script type=&quot;math/tex&quot;&gt;\lambda_{i}&lt;/script&gt;’s (a.k.a. Singular Values, hence the name of SVD), and they are by default sorted in descending order. Usually we’d re-represent the original matrix by keeping only the largest Singular Values, and truncate &lt;code class=&quot;highlighter-rouge&quot;&gt;u&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;vh&lt;/code&gt; accordingly. This is known as &lt;strong&gt;Truncated SVD&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Code:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;truncated_svd_3_channel_compression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;`img` is 3-D array of shape [height, width, channels]
  `t` is the number of singular values to keep
  &quot;&quot;&quot;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;u0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vh0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;svd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;u1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vh1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;svd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;u2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vh2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;svd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vh0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vh1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vh2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'uint8'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'img.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;truncated_svd_3_channel_compression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Below are the images reconstructed using different number of SV’s as well as the original image. The total number of SV’s is 450 (height of image).&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/n10.jpg&quot; width=&quot;365&quot; /&gt; &lt;img src=&quot;/assets/n20.jpg&quot; width=&quot;365&quot; /&gt;
&lt;br /&gt;
Top 10 (L) and 20 (R) Singular Values
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/n30.jpg&quot; width=&quot;365&quot; /&gt; &lt;img src=&quot;/assets/n40.jpg&quot; width=&quot;365&quot; /&gt;
&lt;br /&gt;
Top 30 (L) and 40 (R) Singular Values
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/n50.jpg&quot; width=&quot;365&quot; /&gt; &lt;img src=&quot;/assets/fountainpark.jpg&quot; width=&quot;365&quot; /&gt;
&lt;br /&gt;
Top 50 (L) Singular Values and orignal image (R)
&lt;/p&gt;

&lt;p&gt;We can see that as we increase the number of singular values, the reconstructed image gets less blurry and contain less “outlier” pixels, and the one reconstructed from only 50 singular values offers great approximation to the orignal image.&lt;/p&gt;</content><author><name></name></author><summary type="html">In the previous post we talked about Principlal Component Analysis, a popular statistical technique for dimensionality reduction and feature decorrelation. Another common use case is matrix decomposition, where a matrix is factorized into a product of matrices (Eigendecomposition).</summary></entry><entry><title type="html">PCA Explained</title><link href="http://localhost:4000/jekyll/update/2016/02/09/PCA.html" rel="alternate" type="text/html" title="PCA Explained" /><published>2016-02-09T23:42:01+08:00</published><updated>2016-02-09T23:42:01+08:00</updated><id>http://localhost:4000/jekyll/update/2016/02/09/PCA</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2016/02/09/PCA.html">&lt;p&gt;In Machine Learning and Statistics, &lt;strong&gt;Principal Component Analysis&lt;/strong&gt; (PCA or linear PCA) is a classic and widely used technique for data transformation. PCA can, for example, transform your high dimensional data into points in two or three dimensional space so that they can be easily visualized in a scatter plot, or it could be a preprocessing step in supervised learning tasks (classification, regression) so that the data is projected in low dimensional space where the new features are decorrelated, leading to potentially better accuracy. This tutorial will explain all the math behind PCA and provide an example where you’ll practice step-by-step how to perform PCA on a synthetic data matrix.&lt;/p&gt;

&lt;h2 id=&quot;prerequisite&quot;&gt;Prerequisite&lt;/h2&gt;

&lt;p&gt;Here it is assumed that you have some basic understanding of Linear Algebra (e.g. matrix arithmetics, the geometric interpretation of inner product), Calculus (e.g. Lagrangian Multiplier) and Statistics (e.g. what is mean and variance). In addition, definitions of some math concepts and theorems (listed below) are needed to prove the properties of the resulting transformed data matrix.&lt;/p&gt;

&lt;h4 id=&quot;definition-1&quot;&gt;Definition 1&lt;/h4&gt;
&lt;p&gt;A scalar &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; is called an &lt;em&gt;eigenvalue&lt;/em&gt; of a &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt; if there is a nontrivial (non-zero) solution &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A} \mathbf{x} = \lambda \mathbf{x}&lt;/script&gt;. Such an &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; is called an &lt;em&gt;eigenvector&lt;/em&gt; corresponding to the eigenvalue &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;definition-2&quot;&gt;Definition 2&lt;/h4&gt;
&lt;p&gt;A real-valued &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; symmetric matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt; is said to be &lt;em&gt;positive semidefinite&lt;/em&gt; if the scalar &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}^{T} \mathbf{A} \mathbf{x}&lt;/script&gt; is non-negative for every non-zero real-valued column vector &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;theorem-1&quot;&gt;Theorem 1&lt;/h4&gt;
&lt;p&gt;If &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt; is a real-valued &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; symmetric matrix, then the eigenvectors corresponding to &lt;em&gt;different&lt;/em&gt; eigenvalues must be orthogonal to each other.&lt;/p&gt;

&lt;p&gt;[http://www.math.hawaii.edu/~lee/linear/eigen.pdf]&lt;/p&gt;
&lt;h4 id=&quot;theorem-2&quot;&gt;Theorem 2&lt;/h4&gt;
&lt;p&gt;A real-valued &lt;script type=&quot;math/tex&quot;&gt;n \times n&lt;/script&gt; symmetric matrix is positive semidefinite if and only if all of its eigenvalues are non-negative.&lt;/p&gt;

&lt;p&gt;[http://theanalysisofdata.com/probability/C4.html]&lt;/p&gt;
&lt;h2 id=&quot;the-math&quot;&gt;The Math&lt;/h2&gt;

&lt;p&gt;Let’s say we have a &lt;script type=&quot;math/tex&quot;&gt;n \times d&lt;/script&gt; data matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; is the number of observations and &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; is the number of features — each observation is described by &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; attributes.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\mathbf{X} =
 \begin{pmatrix}
  x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} \\
  x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} \\
  \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots  \\
  x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nd} 
 \end{pmatrix} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now we wish to describe each observation by a single attribute. In other words, the &lt;script type=&quot;math/tex&quot;&gt;n \times d&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; will be turned into a &lt;script type=&quot;math/tex&quot;&gt;n \times 1&lt;/script&gt; column matrix (i.e. vector), and we want the variance of the sample composed of the &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; elements from this vector to be as large as possible.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;/assets/projection.png&quot; width=&quot;400&quot; /&gt;
  &lt;br /&gt;Project points from 2-D space to 1-D space
&lt;/p&gt;

&lt;p&gt;One way to do this (in the case of PCA) is to project the collection of &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; points in &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;-dimensional space into 1-dimensional space, or equivalently right-multiply &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; with a column vector &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol \alpha= \left( a_{1}, a_{2}, \cdots, a_{d} \right)^{T}&lt;/script&gt;

&lt;p&gt;giving rise to the &lt;script type=&quot;math/tex&quot;&gt;n \times 1&lt;/script&gt; transformed data matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{Y}&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{Y} = \mathbf{X} \boldsymbol \alpha = 
	\begin{pmatrix}
		x_{11}a_{1} + x_{12}a_{2} + \cdots + x_{1d}a_{d}\\
		x_{21}a_{1} + x_{22}a_{2} + \cdots + x_{2d}a_{d}\\
		\vdots \\
		x_{n1}a_{1} + x_{n2}a_{2} + \cdots + x_{nd}a_{d} 
	\end{pmatrix} =
	\begin{pmatrix}
		\sum_{j=1}^{d}x_{1j}a_{j} \\
		\sum_{j=1}^{d}x_{2j}a_{j} \\
		\vdots \\
		\sum_{j=1}^{d}x_{nj}a_{j}
	\end{pmatrix} =
	\begin{pmatrix}
	y_{1} \\
	y_{2} \\
	\vdots \\
	y_{n}
	\end{pmatrix}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For mathmatical convenience, the data matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; is assumed to have been &lt;strong&gt;centered&lt;/strong&gt; (each column sums to one): &lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^{n} x_{ij} = 0&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;j=1 \dotsc d&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;In case &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; had not been centered, you can simply subtract the column-mean from each element in each column.&lt;/p&gt;

&lt;p&gt;Given that &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; has been centered, the transformed data matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{Y}&lt;/script&gt; will be centered as well:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\mathbf{\bar{Y}} &amp;=\frac{1}{n} \sum_{i=1}^{n} y_{i} = \frac{1}{n} \sum_{i=1}^{n} \left(  \sum_{j=1}^{d} x_{ij}a_{j}  \right) = \frac{1}{n} \sum_{j=1}^{d}  \left(  \sum_{i=1}^{n} x_{ij}a_{j}  \right) \\
        &amp;=  \frac{1}{n} \sum_{j=1}^{d}  a_{j}\left(  \sum_{i=1}^{n} x_{ij}  \right) =  \frac{1}{n} \sum_{j=1}^{d}  a_{j}\cdot 0 = 0
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Remember we wanted to make the variance of the sample composed of the &lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; elements from &lt;script type=&quot;math/tex&quot;&gt;\mathbf{Y}&lt;/script&gt; to be as large as possible. In other words, we want to maximize &lt;script type=&quot;math/tex&quot;&gt;\textrm{Var}(\mathbf{Y})&lt;/script&gt; (over the space of all &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt;), which can be expressed in terms of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\textrm{Var}(\mathbf{Y}) &amp; = \frac{1}{n - 1} \sum_{i=1}^{n} \left( y_{i} - \mathbf{\bar{Y}} \right)^{2}=\frac{1}{n -1}\sum_{i=1}^{n}y_{i}^{2} \\ 
  &amp; = \frac{1}{n - 1}\mathbf{Y}^{T}\mathbf{Y}=\boldsymbol\alpha^{T}\left( \frac{1}{n-1} \mathbf{X}^{T}\mathbf{X} \right) \boldsymbol\alpha
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;Here we can see that &lt;script type=&quot;math/tex&quot;&gt;\textrm{Var}(\mathbf{Y})&lt;/script&gt; is proportional to the norm of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{Y}&lt;/script&gt;, which in turn depends on the norm of &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt;. If we were to allow the norm of &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt; to be unbounded, the &lt;script type=&quot;math/tex&quot;&gt;\textrm{Var}(\mathbf{Y})&lt;/script&gt; could be arbitrarily large!&lt;/p&gt;

&lt;p&gt;To fix this we need to put some constraint on &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt; — we make it a unit-length vector: &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\alpha^{T} \boldsymbol\alpha = \sum_{j=1}^{d}a_{j}^{2} = 1&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;So this turns the original function optimization problem into one with an equality constraint, which can be solved using &lt;a href=&quot;https://en.wikipedia.org/wiki/Lagrange_multiplier&quot;&gt;Lagrangian Multiplier&lt;/a&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\boldsymbol\alpha, \lambda) = \boldsymbol\alpha^{T} \left( \frac{1}{n - 1}  \mathbf{X}^{T} \mathbf{X} \right) \boldsymbol\alpha - \lambda \left(\boldsymbol\alpha^{T} \boldsymbol\alpha - 1\right)&lt;/script&gt;

&lt;p&gt;Taking the derivative of the Lagrangian function &lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; with respect to &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt; and set it to zero,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\frac{\partial}{\partial \boldsymbol\alpha} L(\boldsymbol\alpha, \lambda) &amp; =  \frac{1}{n - 1}  \mathbf{X}^{T} \mathbf{X} \boldsymbol\alpha + \frac{1}{n - 1} \left( \mathbf{X}^{T} \mathbf{X} \right)^{T} \boldsymbol\alpha - \lambda \cdot 2 \boldsymbol \alpha \\ 
&amp; = \frac{2}{n - 1} \mathbf{X}^{T} \mathbf{X} \cdot \boldsymbol\alpha - 2 \lambda \cdot \boldsymbol\alpha = 0
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;we end up with the condition that &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt; must statisfy:&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol\Sigma \boldsymbol\alpha = \lambda \boldsymbol\alpha&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\Sigma = \frac{1}{n - 1}  \mathbf{X}^{T} \mathbf{X}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;According to &lt;strong&gt;Defitition 1&lt;/strong&gt;, &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt; must be an eigenvector of &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \Sigma&lt;/script&gt; corresponding to eigenvalue &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We can further show that the variance of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{Y}&lt;/script&gt; happens to be equal to &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textrm{Var}(\mathbf{Y}) = \boldsymbol\alpha^{T}\left( \frac{1}{n-1} \mathbf{X}^{T}\mathbf{X} \right) \boldsymbol\alpha = \boldsymbol\alpha^{T} \boldsymbol\Sigma \boldsymbol\alpha = \boldsymbol\alpha^{T} \lambda \boldsymbol\alpha = \lambda \cdot 1 = \lambda&lt;/script&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;The &lt;script type=&quot;math/tex&quot;&gt;d\times d&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \Sigma&lt;/script&gt; (i.e. the covariance matrix of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt;) has the following properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\Sigma = \frac{1}{n-1} \mathbf{X}^{T} \mathbf{X}&lt;/script&gt; is symmetric: &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \Sigma ^{T} = \left( \frac{1}{n-1} \mathbf{X}^{T} \mathbf{X} \right)^{T} = \frac{1}{n-1} \mathbf{X}^{T} \mathbf{X} = \boldsymbol\Sigma&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\Sigma = \frac{1}{n-1} \mathbf{X}^{T} \mathbf{X}&lt;/script&gt; is semi-positive definite: For any real-valued non-zero vector &lt;script type=&quot;math/tex&quot;&gt;\mathbf{w} = \left(w_{1}, w_{2}, \cdots, w_{d} \right)^{T}&lt;/script&gt;,&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w}^{T} \boldsymbol\Sigma \mathbf{w} = \mathbf{w}^{T} \frac{1}{n-1} \mathbf{X}^{T} \mathbf{X} \mathbf{w} = \frac{1}{n-1} \left( \mathbf{X} \mathbf{w} \right)^{T} \mathbf{X} \mathbf{w} = \frac{1}{n-1} \Vert \mathbf{X} \mathbf{w} \Vert ^{2} \ge 0&lt;/script&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Suppose &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1}, \lambda_{2}, \cdots, \lambda_{d}&lt;/script&gt; are the eigenvalues of &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \Sigma&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;\{\boldsymbol \alpha_{1i_{1}}\}, \{\boldsymbol \alpha_{2i_{2}}\}, \cdots, \{\boldsymbol \alpha_{di_{d}}\}&lt;/script&gt; are the sets of eigenvectors corresponding to each eigenvalue. Then &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; must be one of the eigenvalues, and &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha&lt;/script&gt; must be an eigenvector corresponding to &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;According to &lt;strong&gt;Theorem 1&lt;/strong&gt;, we know that eigenvectors &lt;script type=&quot;math/tex&quot;&gt;\{\boldsymbol \alpha_{1i_{1}}\}, \{\boldsymbol \alpha_{2i_{2}}\}, \cdots, \{\boldsymbol \alpha_{di_{d}}\}&lt;/script&gt; are orthogonal to each other.
&lt;br /&gt;
According to &lt;strong&gt;Theorem 2&lt;/strong&gt;, we know that the eigenvalues are non-negative — &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1} \ge 0, \lambda_{2} \ge 0, \cdots, \lambda_{d} \ge 0&lt;/script&gt;&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;Based on the properties of &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\Sigma&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\alpha&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;, and &lt;script type=&quot;math/tex&quot;&gt;\textrm{Var}(\mathbf{Y})&lt;/script&gt;, we can apply PCA on &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; in the following steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the covariance matrix &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\Sigma = \frac{1}{n - 1}  \mathbf{X}^{T} \mathbf{X}&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}&lt;/script&gt; should have been centered.&lt;/li&gt;
  &lt;li&gt;Find the eigenvalues &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1}, \lambda_{2}, \cdots, \lambda_{d}&lt;/script&gt; of &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol\Sigma&lt;/script&gt;, as well as the corresponding eigenvectors &lt;script type=&quot;math/tex&quot;&gt;\boldsymbol \alpha_{1}, \boldsymbol \alpha_{2}, \cdots, \boldsymbol \alpha_{d}&lt;/script&gt;. The eigenvalues should be in descending order: &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1} \ge \lambda_{2} \ge \cdots \ge \lambda_{d}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Determine the number of features &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; to keep in the transformed matrix (&lt;script type=&quot;math/tex&quot;&gt;1 \le k \le d&lt;/script&gt;).&lt;/li&gt;
  &lt;li&gt;Build the &lt;script type=&quot;math/tex&quot;&gt;d \times k&lt;/script&gt; matrix &lt;script type=&quot;math/tex&quot;&gt;M = \left( \boldsymbol \alpha_{1}, \boldsymbol \alpha_{2}, \cdots, \boldsymbol \alpha_{k} \right)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Compute the transformed matrix &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}_{pca} = \mathbf{X}M = \left(\mathbf{X\alpha_{1}}, \mathbf{X\alpha_{2}}, \cdots, \mathbf{X\alpha_{k}} \right)&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;And we can prove that the columns of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X}_{pca}&lt;/script&gt; have the properties that we desired:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbf{X\alpha_{1}}&lt;/script&gt; has the largest variance &lt;script type=&quot;math/tex&quot;&gt;\lambda_{1}&lt;/script&gt;, followed by &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X\alpha_{2}}&lt;/script&gt; with variance &lt;script type=&quot;math/tex&quot;&gt;\lambda_{2}&lt;/script&gt;, and so on.&lt;/li&gt;
  &lt;li&gt;The columns of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{X\alpha_{1}}&lt;/script&gt; are orthogonal with each other — Consider &lt;script type=&quot;math/tex&quot;&gt;X\boldsymbol\alpha_{i}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;X\boldsymbol\alpha_{j}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
1 \le i &lt; j \le d %]]&gt;&lt;/script&gt;). It follows that&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align} \left( X\boldsymbol\alpha_{i} \right) ^{T} X\boldsymbol\alpha_{j} &amp; = \boldsymbol\alpha_{i}^{T} X^{T} X \boldsymbol\alpha_{j} = (n-1)\boldsymbol\alpha_{i}^{T} \boldsymbol\Sigma \boldsymbol\alpha_{j}  =(n-1)\boldsymbol\alpha_{i}^{T} \lambda_{j} \boldsymbol\alpha_{j} \\ &amp;=(n-1)\lambda_{j} \boldsymbol\alpha_{i}^{T}  \boldsymbol\alpha_{j} = (n-1)\lambda_{j} \cdot 0 = 0 \end{align} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;example&quot;&gt;Example&lt;/h2&gt;

&lt;p&gt;We conclude our discussion with an example where we’ll generate a synthetic dataset and apply PCA as prescribed above.&lt;/p&gt;

&lt;p&gt;First we will generate 2-D dataset with covariance matrix &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{pmatrix}0.1 &amp; 0.0 \\ 0.0 &amp; 1.0 \end{pmatrix} %]]&gt;&lt;/script&gt; and mean &lt;script type=&quot;math/tex&quot;&gt;(-1, 1)&lt;/script&gt; (shown in the figure below):&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_2Ddata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;covariance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;rot_mat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; 
                      &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]])&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rot_mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_2Ddata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Compute covariance matrix of a centered data matrix&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Center the data 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Compute covariance matrix
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Find the eigenvalues and eigenvectors, and sort them in descending order of eigenvalues.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# eigval[i] is the ith eigenvalue
# eigvec[:, i] is the eigenvector corresponding to eigval[i]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;eigvec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For now we’ll keep all principle components, but you can keep the top &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt; components with largest variance:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;eigvec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Apply PCA as a linear transformation on &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;X_pca&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigvec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Display PCA-transfomred data matrix in scatter plot&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_pca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_pca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'1st Principal Component'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'2nd Principal Component'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/assets/pca.png&quot; width=&quot;1200&quot; /&gt;
&lt;br /&gt;
Left: Original, uncentered. Middle: Centered. Right: PCA-transformed
&lt;/p&gt;</content><author><name></name></author><summary type="html">In Machine Learning and Statistics, Principal Component Analysis (PCA or linear PCA) is a classic and widely used technique for data transformation. PCA can, for example, transform your high dimensional data into points in two or three dimensional space so that they can be easily visualized in a scatter plot, or it could be a preprocessing step in supervised learning tasks (classification, regression) so that the data is projected in low dimensional space where the new features are decorrelated, leading to potentially better accuracy. This tutorial will explain all the math behind PCA and provide an example where you’ll practice step-by-step how to perform PCA on a synthetic data matrix.</summary></entry></feed>